import matplotlib.pyplot as plt
import numpy as np
import pickle as pkl

def plot_loss_from_file_convnets(path, depth=7):
    '''
        Function to plot the results from previous runs stored in the experimental_results folder.
        
        The path should point to a pickled dictionary with the following structure:
        {
            'model_id'{
                'loss': list,
                'accuracy': list,
                'val_loss': list,
                'val_accuracy': list,
                ...
            }
        }
        
        This is a dictionary where the key is the model id generated by the _get() function for the desired model, and
        the items being the history returned by calling model.fit(). 
    '''
    depth_7_metrics = pkl.load(open(path, 'rb'))

    # Plot the train/test loss and accuracy at the end of training for each model. 
    widths = []
    train_losses = []
    train_accuracy = []
    test_losses = []
    test_accuracy = []


    for model_id, history in depth_7_metrics.items():
        widths.append(int(model_id[23:]))

        train_losses.append(history.get('loss'))
        train_accuracy.append(history.get('accuracy'))
        test_losses.append(history.get('val_loss'))
        test_accuracy.append(history.get('val_accuracy'))    

    train_losses = np.array(train_losses)
    train_accuracy = np.array(train_accuracy)
    test_losses = np.array(test_losses)
    test_accuracy = np.array(test_accuracy)

    # optimal early stopping values
    optimal_test_idx = test_accuracy.argmax(axis=1)
    optimal_early_train_losses = np.array([train_losses[i, idx] for i, idx in enumerate(optimal_test_idx)])
    optimal_early_train_accuracy = np.array([train_accuracy[i, idx] for i, idx in enumerate(optimal_test_idx)])
    optimal_early_test_losses = np.array([test_losses[i, idx] for i, idx in enumerate(optimal_test_idx)])
    optimal_early_test_accuracy = np.array([test_accuracy[i, idx] for i, idx in enumerate(optimal_test_idx)])

    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))

    train_loss_plt = axes[0][0]
    test_loss_plt = axes[0][1]
    train_accy_plt = axes[1][0]
    test_accy_plt = axes[1][1]

    fig.suptitle(f'Depth {depth} Conv Net Results:', fontsize=24, fontweight='bold')

    train_loss_plt.plot(widths, train_losses[:,-1], marker='o', markersize=4, label='Final Train Loss')
    train_loss_plt.plot(widths, optimal_early_train_losses, marker='o', markersize=4, label='Optimal Early Stopping Train Loss')
    train_loss_plt.set_ylabel('Train Loss', fontsize=16)

    test_loss_plt.plot(widths, test_losses[:,-1], marker='o', markersize=4, label='Final Test Loss')
    test_loss_plt.plot(widths, optimal_early_test_losses, marker='o', markersize=4, label='Optimal Early Stopping Test Loss')
    test_loss_plt.set_ylabel('Test Loss', fontsize=16)

    train_accy_plt.plot(widths, 100*(1 - train_accuracy[:,-1]), marker='o', markersize=4, label='Final Train Accuracy')
    train_accy_plt.plot(widths, 100*(1 - optimal_early_train_accuracy), marker='o', markersize=4, label='Optimal Early Stopping Train Accuracy')
    train_accy_plt.set_ylabel('Train Accuracy', fontsize=16)

    test_accy_plt.plot(widths, 100*(1 - test_accuracy[:,-1]), marker='o', markersize=4, label='Final Test Accuracy')
    test_accy_plt.plot(widths, 100*(1 - optimal_early_test_accuracy), marker='o', markersize=4, label='Optimal Early Stopping Test Accuracy')
    test_accy_plt.set_ylabel('Test Accuracy', fontsize=16)

    for ax in axes.flatten():
        ax.set_xlabel('Layer Width', fontsize=16)
        ax.legend(fontsize=14)
        ax.grid(alpha=0.5)

    fig.tight_layout(pad=1.15, h_pad=2)
    plt.show()