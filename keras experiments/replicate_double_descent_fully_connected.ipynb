{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "replicate_double_descent_fully_connected.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komPxXzy6oTT",
        "outputId": "bfeb6b8a-8c72-4bc8-99f3-9636af25d96c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.layers import Dense, Flatten \n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYkDDKhP6ozO"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqNW9NH6rvs"
      },
      "source": [
        "# paper's fully connected model learned on a subset of MNIST (n = 4000, d = 784, K = 10 classes)\n",
        "x_train, y_train = x_train[:4000], y_train[:4000]\n",
        "x_test, y_test = x_test[:4000], y_test[:4000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y6-hXm1t6vf_",
        "outputId": "c7e98abc-be74-43d4-8560-d60bd16929b6"
      },
      "source": [
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "def lr_decay(epoch, lr):\n",
        "    return lr * 0.9**(epoch//500)\n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
        "\n",
        "# For networks smaller than the interpolation threshold, training is stopped after classification error reached zero or 6000 epochs,\n",
        "class CustomCallback_epoch(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      if logs[\"accuracy\"]==1:\n",
        "        self.model.stop_training = True\n",
        "        print('STOPPING EARLY AFTER INTERPOLATING AT EPOCH %d' %epoch)\n",
        "        print('INTERPOLATION THRESHOLD REACHED')\n",
        "\n",
        "history_logs = []\n",
        "saved_weights = []\n",
        "\n",
        "num_parameters = [i*1000 for i in [3, 6, 9, 12, 24, 28, 32, 34, 36, 38, 40, 42, 46, 50, 80, 150, 300, 800]]\n",
        "hidden_sizes = [(N-10)//795 for N in num_parameters]\n",
        "for N in num_parameters:\n",
        "  print('='*80)\n",
        "  print('Number of parameters = %d, %d hidden layer neurons' %(N, (N-10)//795)) \n",
        "  print('='*80)\n",
        "\n",
        "  # P = (d+1)·H+(H+1)·K = 785H+10H+10 = 795H+10 --> H = (P-10)/795\n",
        "  num_nodes = (N-10)//795\n",
        "  # The remaining weights are initialized with normally distributed random numbers (mean 0 and variance 0.01). The smallest network is initialized using standard Glorotuniform distribution [19].\n",
        "  normal_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01**0.5)\n",
        "  glorot_initializer = tf.keras.initializers.GlorotUniform()  \n",
        "  # if this is the first model (smallest network) use standard Glorotuniform, otherwise use random normal\n",
        "  initializer = normal_initializer if saved_weights else glorot_initializer\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(num_nodes, activation='relu', kernel_initializer=initializer, bias_initializer=initializer),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer, bias_initializer=initializer)\n",
        "  ])\n",
        "\n",
        "  # paper used SGD with standard momentum (parameter value 0.95)\n",
        "  opt = tf.keras.optimizers.SGD(momentum=0.95)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  # print(model.weights[0].shape)\n",
        "  # print(model.weights[1].shape)\n",
        "  # # print(model.weights[1])\n",
        "  # print(model.weights[2].shape)\n",
        "  # # print(model.weights[2])\n",
        "  # print(model.weights[3].shape)\n",
        "  # # print(model.weights[3])\n",
        "\n",
        "  # from paper: To train a larger network with H2 > H1 hidden units, we initialize the first H1 hidden units of the larger network to the weights learned in the smaller network.  \n",
        "  # equivalently, here we expand saved weight with H1 units from prev model with randomly initialized weight for the new hidden units from the new model, then re-assign the combined weights to the new model\n",
        "  if saved_weights: \n",
        "    prev_weights = saved_weights[-1]\n",
        "    tf.compat.v1.assign(model.weights[0], tf.concat((prev_weights[0], model.weights[0][:, prev_weights[0].shape[1]:]), axis=1))\n",
        "    tf.compat.v1.assign(model.weights[1], tf.concat((prev_weights[1], model.weights[1][prev_weights[1].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[2], tf.concat((prev_weights[2], model.weights[2][prev_weights[2].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[3], prev_weights[3])\n",
        "\n",
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs,\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "\n",
        "  interpolated = history_logs and max([h[1].history['loss'] for h in history_logs])[0] == 1.0\n",
        "\n",
        "  # The expected interpolation threshold: paper observed it at n · K = 4000 * 10 = 40000\n",
        "  # interpolated = N >= 40000\n",
        "\n",
        "  if not interpolated:\n",
        "    history = model.fit(x_train, y_train, epochs=6000, validation_data=(x_test, y_test), verbose=0, callbacks=[CustomCallback_epoch(), scheduler])\n",
        "  else:\n",
        "    history = model.fit(x_train, y_train, epochs=6000, validation_data=(x_test, y_test), verbose=0)\n",
        "  \n",
        "  saved_weights.append(model.weights)\n",
        "\n",
        "  history_logs.append((N, history))\n",
        "  print(tf.math.confusion_matrix(y_test, tf.argmax(model.predict(x_test), axis=1)))\n",
        "  model.summary()\n",
        "  print('max training accuracy', max(history.history['accuracy']))\n",
        "  print('min training loss', min(history.history['loss']))\n",
        "  print('max validation accuracy', max(history.history['val_accuracy']))\n",
        "  print('min validation loss', min(history.history['val_loss']))\n",
        "  print()\n",
        "  print('last training accuracy', history.history['accuracy'][-1])\n",
        "  print('last training loss', history.history['loss'][-1])\n",
        "  print('last validation accuracy', history.history['val_accuracy'][-1])\n",
        "  print('last validation loss', history.history['val_loss'][-1])\n",
        "  \n",
        "# plot errors over number of parameters\n",
        "plt.title('Training and validation error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['val_accuracy'][-1] for i in history_logs], color='blue', label='val_error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['accuracy'][-1] for i in history_logs], color='orange', label='training error')\n",
        "plt.xlabel('Number of parameters N(*10^3)')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Number of parameters = 3000, 3 hidden layer neurons\n",
            "================================================================================\n",
            "tf.Tensor(\n",
            "[[205   7   3   2  55  19  65   0  14   0]\n",
            " [  1 384  12   3   0   4   6   0  40   0]\n",
            " [  3  50 258  81   3   1  10   5   7   0]\n",
            " [  2   3  56 231  10  18   0  32  53   3]\n",
            " [ 31   1   0   1 288  11   4   3   2  77]\n",
            " [ 59  11   7  19 120  59   6  11  58  22]\n",
            " [ 57  27   3   0   5   3 276   0   4   3]\n",
            " [  3   4   5  46  13   3   0 246  13  78]\n",
            " [ 45  51  13  45  33  54  11  10 112  10]\n",
            " [  8   0   0   3 102  15   1  34   4 224]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_101 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_202 (Dense)            (None, 3)                 2355      \n",
            "_________________________________________________________________\n",
            "dense_203 (Dense)            (None, 10)                40        \n",
            "=================================================================\n",
            "Total params: 2,395\n",
            "Trainable params: 2,395\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.7472500205039978\n",
            "min training loss 0.7434120774269104\n",
            "max validation accuracy 0.5842499732971191\n",
            "min validation loss 1.3377383947372437\n",
            "\n",
            "last training accuracy 0.7434999942779541\n",
            "last training loss 0.7434126138687134\n",
            "last validation accuracy 0.5707499980926514\n",
            "last validation loss 1.611209750175476\n",
            "================================================================================\n",
            "Number of parameters = 6000, 7 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 306\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[326   0  10   1   2   9  11   6   4   1]\n",
            " [  0 431   1   6   1   0   4   4   3   0]\n",
            " [  3   9 323  32   0   3   5  24  16   3]\n",
            " [  2   8  13 315   1  36   0  17   8   8]\n",
            " [  0   1   4   3 361   2  11   3   5  28]\n",
            " [ 22   4   8  24   8 270   7   4  14  11]\n",
            " [ 14   4  25   1  18  18 290   2   5   1]\n",
            " [  2   9  10   6   5   0   1 349   4  25]\n",
            " [  6  10  16  19   6  30   5   4 271  17]\n",
            " [  3   2   3  11  29   4   0  19  17 303]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_102 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_204 (Dense)            (None, 7)                 5495      \n",
            "_________________________________________________________________\n",
            "dense_205 (Dense)            (None, 10)                80        \n",
            "=================================================================\n",
            "Total params: 5,575\n",
            "Trainable params: 5,575\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0024741627275943756\n",
            "max validation accuracy 0.8330000042915344\n",
            "min validation loss 0.8689254522323608\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0024778475053608418\n",
            "last validation accuracy 0.8097500205039978\n",
            "last validation loss 2.0680696964263916\n",
            "================================================================================\n",
            "Number of parameters = 9000, 11 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 1\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[325   0  10   1   2   9  12   6   4   1]\n",
            " [  0 431   1   6   1   0   4   4   3   0]\n",
            " [  3   9 319  36   0   4   5  24  15   3]\n",
            " [  2   8  13 317   0  37   0  16   8   7]\n",
            " [  0   1   4   3 360   2  12   3   5  28]\n",
            " [ 22   3   7  24   8 272   7   4  14  11]\n",
            " [ 13   4  24   1  18  19 292   2   4   1]\n",
            " [  2   9  10   8   5   0   1 347   4  25]\n",
            " [  6  10  16  20   5  31   6   4 269  17]\n",
            " [  3   2   4  11  30   4   0  19  15 303]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_103 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_206 (Dense)            (None, 11)                8635      \n",
            "_________________________________________________________________\n",
            "dense_207 (Dense)            (None, 10)                120       \n",
            "=================================================================\n",
            "Total params: 8,755\n",
            "Trainable params: 8,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0024962136521935463\n",
            "max validation accuracy 0.8102499842643738\n",
            "min validation loss 2.0606837272644043\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0024962136521935463\n",
            "last validation accuracy 0.8087499737739563\n",
            "last validation loss 2.075413227081299\n",
            "================================================================================\n",
            "Number of parameters = 12000, 15 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0  10   1   2   7  12   6   4   1]\n",
            " [  0 431   1   5   1   0   5   4   3   0]\n",
            " [  3   9 325  32   0   3   5  22  16   3]\n",
            " [  2   8  14 313   1  37   0  17   9   7]\n",
            " [  0   1   4   3 361   2  12   3   5  27]\n",
            " [ 22   4   8  19   8 271   7   4  18  11]\n",
            " [ 14   4  22   1  18  19 293   2   5   0]\n",
            " [  2   9  11   6   5   0   1 347   6  24]\n",
            " [  6   9  16  19   5  30   6   4 272  17]\n",
            " [  3   2   3  11  31   4   0  19  17 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_104\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_104 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_208 (Dense)            (None, 15)                11775     \n",
            "_________________________________________________________________\n",
            "dense_209 (Dense)            (None, 10)                160       \n",
            "=================================================================\n",
            "Total params: 11,935\n",
            "Trainable params: 11,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002457114402204752\n",
            "max validation accuracy 0.8102499842643738\n",
            "min validation loss 2.060371160507202\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002457114402204752\n",
            "last validation accuracy 0.8102499842643738\n",
            "last validation loss 2.060371160507202\n",
            "================================================================================\n",
            "Number of parameters = 24000, 30 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   9   1   2   8  11   6   4   1]\n",
            " [  0 430   1   6   1   0   5   4   3   0]\n",
            " [  3   9 327  31   0   3   5  22  15   3]\n",
            " [  2   8  14 311   1  39   0  17   9   7]\n",
            " [  0   1   4   3 362   2  12   3   5  26]\n",
            " [ 22   4   7  19   8 272   7   4  18  11]\n",
            " [ 14   5  26   1  19  18 287   2   6   0]\n",
            " [  2   8  12   7   5   0   1 346   4  26]\n",
            " [  6   8  16  19   5  30   5   4 274  17]\n",
            " [  3   2   3  11  32   4   0  19  16 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_105\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_105 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_210 (Dense)            (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dense_211 (Dense)            (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 23,860\n",
            "Trainable params: 23,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0026401467621326447\n",
            "max validation accuracy 0.809499979019165\n",
            "min validation loss 2.065609931945801\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0026401467621326447\n",
            "last validation accuracy 0.809499979019165\n",
            "last validation loss 2.065609931945801\n",
            "================================================================================\n",
            "Number of parameters = 28000, 35 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[325   0  10   1   2   8  13   6   4   1]\n",
            " [  0 431   1   5   1   0   5   4   3   0]\n",
            " [  3   9 324  32   0   3   5  24  15   3]\n",
            " [  2   8  14 314   1  37   0  17   8   7]\n",
            " [  0   1   4   3 360   2  12   3   5  28]\n",
            " [ 22   4   8  20   8 271   7   4  17  11]\n",
            " [ 14   5  26   1  18  16 290   2   5   1]\n",
            " [  2   8  10   7   5   0   1 349   4  25]\n",
            " [  6  10  16  19   6  30   5   4 271  17]\n",
            " [  3   2   4  11  31   4   0  19  15 302]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_106\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_106 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_212 (Dense)            (None, 35)                27475     \n",
            "_________________________________________________________________\n",
            "dense_213 (Dense)            (None, 10)                360       \n",
            "=================================================================\n",
            "Total params: 27,835\n",
            "Trainable params: 27,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002429467858746648\n",
            "max validation accuracy 0.809249997138977\n",
            "min validation loss 2.074965715408325\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002429467858746648\n",
            "last validation accuracy 0.809249997138977\n",
            "last validation loss 2.074965715408325\n",
            "================================================================================\n",
            "Number of parameters = 32000, 40 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[324   0  10   1   2   9  13   6   4   1]\n",
            " [  0 431   1   5   1   0   5   4   3   0]\n",
            " [  3   9 324  32   0   3   5  23  16   3]\n",
            " [  2   8  14 311   1  40   0  17   8   7]\n",
            " [  0   1   4   3 363   2  11   3   4  27]\n",
            " [ 21   4   7  20   8 272   7   4  18  11]\n",
            " [ 13   5  26   1  19  19 288   2   5   0]\n",
            " [  2   8  10   7   5   0   1 350   4  24]\n",
            " [  6  10  16  19   6  31   5   4 270  17]\n",
            " [  3   2   4  11  32   4   0  19  15 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_107\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_107 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_214 (Dense)            (None, 40)                31400     \n",
            "_________________________________________________________________\n",
            "dense_215 (Dense)            (None, 10)                410       \n",
            "=================================================================\n",
            "Total params: 31,810\n",
            "Trainable params: 31,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002468016929924488\n",
            "max validation accuracy 0.8084999918937683\n",
            "min validation loss 2.0748910903930664\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002468016929924488\n",
            "last validation accuracy 0.8084999918937683\n",
            "last validation loss 2.0748910903930664\n",
            "================================================================================\n",
            "Number of parameters = 34000, 42 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[325   0  10   1   2   9  12   6   4   1]\n",
            " [  0 431   1   5   1   0   5   4   3   0]\n",
            " [  3   9 320  35   0   3   5  24  16   3]\n",
            " [  2   8  13 318   0  36   0  16   8   7]\n",
            " [  0   1   4   3 361   2  12   3   5  27]\n",
            " [ 20   4   7  20   8 273   7   4  18  11]\n",
            " [ 13   5  24   1  19  17 292   2   5   0]\n",
            " [  2   8  10   9   5   0   1 347   4  25]\n",
            " [  6  10  16  19   5  30   6   4 271  17]\n",
            " [  3   2   4  11  32   4   0  19  15 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_108\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_108 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_216 (Dense)            (None, 42)                32970     \n",
            "_________________________________________________________________\n",
            "dense_217 (Dense)            (None, 10)                430       \n",
            "=================================================================\n",
            "Total params: 33,400\n",
            "Trainable params: 33,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002411152934655547\n",
            "max validation accuracy 0.8097500205039978\n",
            "min validation loss 2.0734121799468994\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002411152934655547\n",
            "last validation accuracy 0.8097500205039978\n",
            "last validation loss 2.0734121799468994\n",
            "================================================================================\n",
            "Number of parameters = 36000, 45 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0  10   1   2   9  11   6   3   1]\n",
            " [  0 430   1   6   1   0   5   4   3   0]\n",
            " [  3   9 322  34   0   3   5  24  15   3]\n",
            " [  2   8  13 315   1  37   0  17   8   7]\n",
            " [  0   1   4   3 364   2  10   3   4  27]\n",
            " [ 22   4   7  21   8 270   7   4  18  11]\n",
            " [ 14   5  26   1  19  18 288   2   5   0]\n",
            " [  2   8  10   7   5   0   1 348   4  26]\n",
            " [  6  10  16  19   6  31   5   4 270  17]\n",
            " [  3   2   4  11  32   4   0  19  15 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_109\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_109 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_218 (Dense)            (None, 45)                35325     \n",
            "_________________________________________________________________\n",
            "dense_219 (Dense)            (None, 10)                460       \n",
            "=================================================================\n",
            "Total params: 35,785\n",
            "Trainable params: 35,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002353606978431344\n",
            "max validation accuracy 0.8087499737739563\n",
            "min validation loss 2.0824244022369385\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002353606978431344\n",
            "last validation accuracy 0.8087499737739563\n",
            "last validation loss 2.0824244022369385\n",
            "================================================================================\n",
            "Number of parameters = 38000, 47 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0  10   1   2   9  11   6   3   1]\n",
            " [  0 430   1   6   1   0   5   4   3   0]\n",
            " [  3   9 325  33   0   3   5  24  12   4]\n",
            " [  2   8  13 316   1  35   0  17   8   8]\n",
            " [  0   1   4   3 363   2  10   3   4  28]\n",
            " [ 22   4   8  24   8 270   7   4  14  11]\n",
            " [ 14   6  26   1  19  18 286   2   5   1]\n",
            " [  2   8  10   7   5   0   1 348   4  26]\n",
            " [  6  10  17  20   7  31   5   4 267  17]\n",
            " [  3   2   3  11  29   4   0  19  16 304]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_110\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_110 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_220 (Dense)            (None, 47)                36895     \n",
            "_________________________________________________________________\n",
            "dense_221 (Dense)            (None, 10)                480       \n",
            "=================================================================\n",
            "Total params: 37,375\n",
            "Trainable params: 37,375\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002352189039811492\n",
            "max validation accuracy 0.8090000152587891\n",
            "min validation loss 2.0872316360473633\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002352189039811492\n",
            "last validation accuracy 0.8090000152587891\n",
            "last validation loss 2.0872316360473633\n",
            "================================================================================\n",
            "Number of parameters = 40000, 50 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[326   0  10   1   2   9  12   6   3   1]\n",
            " [  0 430   1   6   1   0   5   4   3   0]\n",
            " [  3  11 319  35   0   3   5  24  15   3]\n",
            " [  2   8  12 318   1  36   0  16   8   7]\n",
            " [  0   1   4   3 363   2  11   3   4  27]\n",
            " [ 20   4   7  23   8 273   7   4  15  11]\n",
            " [ 13   5  24   1  19  18 292   2   4   0]\n",
            " [  2   9  10   7   5   0   1 346   4  27]\n",
            " [  6  10  16  20   7  31   5   4 268  17]\n",
            " [  3   2   4  11  32   4   0  19  15 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_111\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_111 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_222 (Dense)            (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dense_223 (Dense)            (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 39,760\n",
            "Trainable params: 39,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002295763697475195\n",
            "max validation accuracy 0.8090000152587891\n",
            "min validation loss 2.0847256183624268\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002295763697475195\n",
            "last validation accuracy 0.8090000152587891\n",
            "last validation loss 2.0847256183624268\n",
            "================================================================================\n",
            "Number of parameters = 42000, 52 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[329   0   9   1   2   8  11   6   3   1]\n",
            " [  0 429   1   7   1   0   5   4   3   0]\n",
            " [  3   8 322  35   0   3   5  24  14   4]\n",
            " [  2   8  13 314   1  38   0  17   7   8]\n",
            " [  0   1   4   3 364   2  10   3   4  27]\n",
            " [ 22   4   8  24   8 270   7   4  14  11]\n",
            " [ 14   5  25   1  21  17 289   2   4   0]\n",
            " [  2   8  10   7   5   0   1 349   4  25]\n",
            " [  6  10  16  20   7  31   5   4 268  17]\n",
            " [  3   2   4  11  32   4   0  19  15 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_112\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_112 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_224 (Dense)            (None, 52)                40820     \n",
            "_________________________________________________________________\n",
            "dense_225 (Dense)            (None, 10)                530       \n",
            "=================================================================\n",
            "Total params: 41,350\n",
            "Trainable params: 41,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0022013322450220585\n",
            "max validation accuracy 0.8087499737739563\n",
            "min validation loss 2.0837438106536865\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0022013322450220585\n",
            "last validation accuracy 0.8087499737739563\n",
            "last validation loss 2.0837438106536865\n",
            "================================================================================\n",
            "Number of parameters = 46000, 57 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[326   0  10   1   2   9  12   6   3   1]\n",
            " [  0 431   1   6   1   0   4   4   3   0]\n",
            " [  3   9 323  33   0   3   5  24  14   4]\n",
            " [  2   8  13 315   1  36   0  17   8   8]\n",
            " [  0   1   4   3 362   2  11   3   4  28]\n",
            " [ 22   4   8  24   8 270   7   4  14  11]\n",
            " [ 14   5  26   1  18  16 291   2   4   1]\n",
            " [  2   9  10   6   5   0   1 348   4  26]\n",
            " [  6  10  16  20   6  31   5   4 269  17]\n",
            " [  3   2   3  11  29   4   0  19  16 304]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_113\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_113 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_226 (Dense)            (None, 57)                44745     \n",
            "_________________________________________________________________\n",
            "dense_227 (Dense)            (None, 10)                580       \n",
            "=================================================================\n",
            "Total params: 45,325\n",
            "Trainable params: 45,325\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002198916394263506\n",
            "max validation accuracy 0.8097500205039978\n",
            "min validation loss 2.089919090270996\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002198916394263506\n",
            "last validation accuracy 0.8097500205039978\n",
            "last validation loss 2.089919090270996\n",
            "================================================================================\n",
            "Number of parameters = 50000, 62 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[326   0   9   1   2   8  13   6   4   1]\n",
            " [  0 431   1   5   1   0   5   4   3   0]\n",
            " [  3   9 324  32   0   3   5  24  15   3]\n",
            " [  2   8  14 314   1  36   0  17   8   8]\n",
            " [  0   1   4   3 361   2  12   3   4  28]\n",
            " [ 22   4   7  21   8 268   7   4  19  12]\n",
            " [ 14   5  23   1  18  15 297   2   3   0]\n",
            " [  2   9  12   6   5   0   1 344   4  28]\n",
            " [  6  10  16  19   5  30   6   4 271  17]\n",
            " [  3   2   3  11  32   4   0  19  16 301]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_114\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_114 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_228 (Dense)            (None, 62)                48670     \n",
            "_________________________________________________________________\n",
            "dense_229 (Dense)            (None, 10)                630       \n",
            "=================================================================\n",
            "Total params: 49,300\n",
            "Trainable params: 49,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002252926118671894\n",
            "max validation accuracy 0.809249997138977\n",
            "min validation loss 2.08137583732605\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002252926118671894\n",
            "last validation accuracy 0.809249997138977\n",
            "last validation loss 2.08137583732605\n",
            "================================================================================\n",
            "Number of parameters = 80000, 100 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   9   1   2   8  12   6   3   1]\n",
            " [  1 432   1   5   1   0   4   4   2   0]\n",
            " [  3   9 323  33   0   3   5  23  15   4]\n",
            " [  2   8  13 313   1  38   0  17   8   8]\n",
            " [  0   1   3   3 362   2  12   3   4  28]\n",
            " [ 21   4   8  22   8 272   7   4  15  11]\n",
            " [ 13   5  23   1  18  16 296   2   3   1]\n",
            " [  2   8  11   7   5   0   1 346   4  27]\n",
            " [  6  11  15  19   7  31   5   4 268  18]\n",
            " [  3   2   3  11  29   4   0  19  15 305]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_115\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_115 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_230 (Dense)            (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_231 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002232346683740616\n",
            "max validation accuracy 0.8112499713897705\n",
            "min validation loss 2.084550380706787\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002232346683740616\n",
            "last validation accuracy 0.8112499713897705\n",
            "last validation loss 2.084550380706787\n",
            "================================================================================\n",
            "Number of parameters = 150000, 188 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0   9   2   2   7  12   6   4   1]\n",
            " [  0 430   1   6   1   0   4   5   3   0]\n",
            " [  3   9 325  31   0   3   5  24  15   3]\n",
            " [  3   8  13 311   1  40   0  17   8   7]\n",
            " [  0   1   3   3 361   2  12   3   4  29]\n",
            " [ 22   4   8  23   9 270   7   4  14  11]\n",
            " [ 14   2  26   1  22  17 290   2   4   0]\n",
            " [  2   7  12   7   5   1   1 345   5  26]\n",
            " [  5   9  16  19   6  30   6   4 269  20]\n",
            " [  3   2   3  10  29   4   0  21  16 303]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_116\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_116 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_232 (Dense)            (None, 188)               147580    \n",
            "_________________________________________________________________\n",
            "dense_233 (Dense)            (None, 10)                1890      \n",
            "=================================================================\n",
            "Total params: 149,470\n",
            "Trainable params: 149,470\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0028145634569227695\n",
            "max validation accuracy 0.8077499866485596\n",
            "min validation loss 2.0891387462615967\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0028145634569227695\n",
            "last validation accuracy 0.8077499866485596\n",
            "last validation loss 2.0891387462615967\n",
            "================================================================================\n",
            "Number of parameters = 300000, 377 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 2\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0   9   2   2   7  12   6   4   1]\n",
            " [  0 431   0   7   1   0   3   4   4   0]\n",
            " [  3   8 324  36   0   4   5  19  16   3]\n",
            " [  2   8  12 316   1  41   0  15   7   6]\n",
            " [  0   1   3   5 355   2  12   3   5  32]\n",
            " [ 23   3   7  19   7 272   8   4  18  11]\n",
            " [ 15   2  24   1  18  15 294   2   6   1]\n",
            " [  2   7  12  10   5   1   1 338   5  30]\n",
            " [  6   8  15  21   4  31   7   5 271  16]\n",
            " [  3   2   2  11  27   4   0  15  17 310]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_117\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_117 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_234 (Dense)            (None, 377)               295945    \n",
            "_________________________________________________________________\n",
            "dense_235 (Dense)            (None, 10)                3780      \n",
            "=================================================================\n",
            "Total params: 299,725\n",
            "Trainable params: 299,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002918241312727332\n",
            "max validation accuracy 0.809499979019165\n",
            "min validation loss 2.0947089195251465\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002918241312727332\n",
            "last validation accuracy 0.809499979019165\n",
            "last validation loss 2.0947089195251465\n",
            "================================================================================\n",
            "Number of parameters = 800000, 1006 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 12\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[332   0  11   1   2   8  10   3   1   2]\n",
            " [  0 435   1   5   1   1   4   0   3   0]\n",
            " [  3   5 353  11   1   5   6  17  13   4]\n",
            " [  3   6  12 324   1  37   0  13   6   6]\n",
            " [  0   0   2   1 377   3  10   1   4  20]\n",
            " [ 16   2   4  14  10 291   3   5  16  11]\n",
            " [  9   2  15   0  16  10 324   1   0   1]\n",
            " [  2   9   8   4   6   3   0 351   6  22]\n",
            " [  7   5  13  15   5  20   4   6 298  11]\n",
            " [  3   2   3   7  26   4   1   7  11 327]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_118\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_118 (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_236 (Dense)            (None, 1006)              789710    \n",
            "_________________________________________________________________\n",
            "dense_237 (Dense)            (None, 10)                10070     \n",
            "=================================================================\n",
            "Total params: 799,780\n",
            "Trainable params: 799,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0004250202910043299\n",
            "max validation accuracy 0.8544999957084656\n",
            "min validation loss 1.786357045173645\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0004250202910043299\n",
            "last validation accuracy 0.8529999852180481\n",
            "last validation loss 1.789926290512085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f94f4d7b9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UeLWRLwfiu11",
        "outputId": "ffd4bc36-dc11-4492-9422-f6e0af3ffcf5"
      },
      "source": [
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "def lr_decay(epoch, lr):\n",
        "    return lr * 0.9**(epoch//500)\n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
        "\n",
        "# For networks smaller than the interpolation threshold, training is stopped after classification error reached zero or 6000 epochs,\n",
        "class CustomCallback_epoch(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      if logs[\"accuracy\"]==1:\n",
        "        self.model.stop_training = True\n",
        "        print('STOPPING EARLY AFTER INTERPOLATING AT EPOCH %d' %epoch)\n",
        "        print('INTERPOLATION THRESHOLD REACHED')\n",
        "\n",
        "history_logs = []\n",
        "saved_weights = []\n",
        "\n",
        "num_parameters = [i*1000 for i in [3, 6, 9, 12, 24, 28, 32, 34, 36, 38, 40, 42, 46, 50, 80, 150, 300, 800]]\n",
        "hidden_sizes = [(N-10)//795 for N in num_parameters]\n",
        "for N in num_parameters:\n",
        "  print('='*80)\n",
        "  print('Number of parameters = %d, %d hidden layer neurons' %(N, (N-10)//795)) \n",
        "  print('='*80)\n",
        "\n",
        "  # P = (d+1)·H+(H+1)·K = 785H+10H+10 = 795H+10 --> H = (P-10)/795\n",
        "  num_nodes = (N-10)//795\n",
        "  # The remaining weights are initialized with normally distributed random numbers (mean 0 and variance 0.01). The smallest network is initialized using standard Glorotuniform distribution [19].\n",
        "  normal_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01**0.5)\n",
        "  glorot_initializer = tf.keras.initializers.GlorotUniform()  \n",
        "  # if this is the first model (smallest network) use standard Glorotuniform, otherwise use random normal\n",
        "  initializer = normal_initializer if saved_weights else glorot_initializer\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(num_nodes, activation='relu', kernel_initializer=initializer, bias_initializer=initializer),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer, bias_initializer=initializer)\n",
        "  ])\n",
        "\n",
        "  # paper used SGD with standard momentum (parameter value 0.95)\n",
        "  opt = tf.keras.optimizers.SGD(momentum=0.95)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  # print(model.weights[0].shape)\n",
        "  # print(model.weights[1].shape)\n",
        "  # # print(model.weights[1])\n",
        "  # print(model.weights[2].shape)\n",
        "  # # print(model.weights[2])\n",
        "  # print(model.weights[3].shape)\n",
        "  # # print(model.weights[3])\n",
        "\n",
        "  # from paper: To train a larger network with H2 > H1 hidden units, we initialize the first H1 hidden units of the larger network to the weights learned in the smaller network.  \n",
        "  # equivalently, here we expand saved weight with H1 units from prev model with randomly initialized weight for the new hidden units from the new model, then re-assign the combined weights to the new model\n",
        "  if saved_weights: \n",
        "    prev_weights = saved_weights[-1]\n",
        "    tf.compat.v1.assign(model.weights[0], tf.concat((prev_weights[0], model.weights[0][:, prev_weights[0].shape[1]:]), axis=1))\n",
        "    tf.compat.v1.assign(model.weights[1], tf.concat((prev_weights[1], model.weights[1][prev_weights[1].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[2], tf.concat((prev_weights[2], model.weights[2][prev_weights[2].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[3], prev_weights[3])\n",
        "\n",
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs,\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "\n",
        "  interpolated = history_logs and max([h[1].history['loss'] for h in history_logs])[0] == 1.0\n",
        "\n",
        "  # The expected interpolation threshold: paper observed it at n · K = 4000 * 10 = 40000\n",
        "  # interpolated = N >= 40000\n",
        "\n",
        "  if not interpolated:\n",
        "    history = model.fit(x_train, y_train, epochs=6000, validation_data=(x_test, y_test), verbose=0, callbacks=[CustomCallback_epoch(), scheduler])\n",
        "  else:\n",
        "    history = model.fit(x_train, y_train, epochs=6000, validation_data=(x_test, y_test), verbose=0)\n",
        "  \n",
        "  saved_weights.append(model.weights)\n",
        "\n",
        "  history_logs.append((N, history))\n",
        "  print(tf.math.confusion_matrix(y_test, tf.argmax(model.predict(x_test), axis=1)))\n",
        "  model.summary()\n",
        "  print('max training accuracy', max(history.history['accuracy']))\n",
        "  print('min training loss', min(history.history['loss']))\n",
        "  print('max validation accuracy', max(history.history['val_accuracy']))\n",
        "  print('min validation loss', min(history.history['val_loss']))\n",
        "  print()\n",
        "  print('last training accuracy', history.history['accuracy'][-1])\n",
        "  print('last training loss', history.history['loss'][-1])\n",
        "  print('last validation accuracy', history.history['val_accuracy'][-1])\n",
        "  print('last validation loss', history.history['val_loss'][-1])\n",
        "  \n",
        "# plot errors over number of parameters\n",
        "plt.title('Training and validation error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['val_accuracy'][-1] for i in history_logs], color='blue', label='val_error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['accuracy'][-1] for i in history_logs], color='orange', label='training error')\n",
        "plt.xlabel('Number of parameters N(*10^3)')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Number of parameters = 3000, 3 hidden layer neurons\n",
            "================================================================================\n",
            "tf.Tensor(\n",
            "[[310   0  14   0   3  19  20   2   0   2]\n",
            " [  0 407   2   6   2   3   1   2  16  11]\n",
            " [ 34   7 214  73   6  29   5  10  35   5]\n",
            " [  8  28  58 217   5  24   2  34  26   6]\n",
            " [  8  16   0   0 316   5  16   2   2  53]\n",
            " [ 19   6  32   9  27 156  37  10  62  14]\n",
            " [ 47   3   0   0  19  39 254   1   8   7]\n",
            " [  9   7   3  25  12   2   1 293   3  56]\n",
            " [  3  48  15  20  14  47   9   5 209  14]\n",
            " [  6  21   5   2  71   4   3  40   3 236]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 2355      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                40        \n",
            "=================================================================\n",
            "Total params: 2,395\n",
            "Trainable params: 2,395\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.9010000228881836\n",
            "min training loss 0.3218483328819275\n",
            "max validation accuracy 0.6924999952316284\n",
            "min validation loss 0.9552460312843323\n",
            "\n",
            "last training accuracy 0.9002500176429749\n",
            "last training loss 0.321848601102829\n",
            "last validation accuracy 0.652999997138977\n",
            "last validation loss 2.003610849380493\n",
            "================================================================================\n",
            "Number of parameters = 6000, 7 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 150\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  18   1   4  17   6   1   0   0]\n",
            " [  0 416   5   9   1   0   4   5  10   0]\n",
            " [ 11  15 334  11   3   2   6  20  16   0]\n",
            " [  5   4  16 303   2  43   1  17  11   6]\n",
            " [  8   8   6   1 323   1  11  15  10  35]\n",
            " [ 21   1   4  20  14 262  15   3  21  11]\n",
            " [ 25   4  22   0   9  17 292   3   6   0]\n",
            " [  8   9  10  14  11   0   3 323   5  28]\n",
            " [  7  18  10  24   6  27   6   7 259  20]\n",
            " [  7   4   1  13  19   6   3  16   7 315]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 5495      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                80        \n",
            "=================================================================\n",
            "Total params: 5,575\n",
            "Trainable params: 5,575\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003321400610730052\n",
            "max validation accuracy 0.7877500057220459\n",
            "min validation loss 1.397079586982727\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003358778776600957\n",
            "last validation accuracy 0.7875000238418579\n",
            "last validation loss 2.2105202674865723\n",
            "================================================================================\n",
            "Number of parameters = 9000, 11 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 3\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  14   1   6  17   6   3   0   0]\n",
            " [  0 418   4   9   1   0   4   5   9   0]\n",
            " [ 11  15 326  13   3   2   8  20  20   0]\n",
            " [  5   4  14 305   2  41   1  18  12   6]\n",
            " [  8   7   3   1 330   1  10  16  11  31]\n",
            " [ 22   1   4  21  14 259  15   3  22  11]\n",
            " [ 25   4  21   0   9  17 292   4   6   0]\n",
            " [  7   9   9  13  12   1   3 325   5  27]\n",
            " [  6  17   6  24   6  27   5   7 266  20]\n",
            " [  6   4   1  14  24   5   3  21   7 306]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 11)                8635      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                120       \n",
            "=================================================================\n",
            "Total params: 8,755\n",
            "Trainable params: 8,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0032122572883963585\n",
            "max validation accuracy 0.7875000238418579\n",
            "min validation loss 2.2020950317382812\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0032122572883963585\n",
            "last validation accuracy 0.7875000238418579\n",
            "last validation loss 2.2066493034362793\n",
            "================================================================================\n",
            "Number of parameters = 12000, 15 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 3\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[324   0  14   1   5  17   6   3   0   0]\n",
            " [  0 418   4   9   1   0   4   5   9   0]\n",
            " [ 11  15 326  13   3   3   8  20  19   0]\n",
            " [  5   4  14 307   2  40   1  18  12   5]\n",
            " [  8   7   4   1 327   1  12  16  11  31]\n",
            " [ 21   1   4  22  14 261  15   3  21  10]\n",
            " [ 27   4  20   0   9  17 292   3   6   0]\n",
            " [  6  10   9  14  11   1   4 324   5  27]\n",
            " [  7  18   9  24   6  26   6   8 261  19]\n",
            " [  7   4   1  14  24   5   3  20   7 306]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 15)                11775     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                160       \n",
            "=================================================================\n",
            "Total params: 11,935\n",
            "Trainable params: 11,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0030862786807119846\n",
            "max validation accuracy 0.7885000109672546\n",
            "min validation loss 2.2091588973999023\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0030862786807119846\n",
            "last validation accuracy 0.7864999771118164\n",
            "last validation loss 2.2233524322509766\n",
            "================================================================================\n",
            "Number of parameters = 24000, 30 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[322   0  15   1   6  17   6   3   0   0]\n",
            " [  0 417   5   9   1   0   4   5   9   0]\n",
            " [ 11  14 326  13   3   3   8  20  20   0]\n",
            " [  6   4  13 308   2  40   1  16  12   6]\n",
            " [  8   7   3   1 328   1  11  16  11  32]\n",
            " [ 22   1   4  21  14 259  15   3  22  11]\n",
            " [ 25   4  21   0   9  17 292   4   6   0]\n",
            " [  7   9   9  14  11   1   3 324   5  28]\n",
            " [  6  16   9  26   6  26   5   7 263  20]\n",
            " [  6   4   1  14  24   5   3  19   7 308]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_5 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 23,860\n",
            "Trainable params: 23,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0030548316426575184\n",
            "max validation accuracy 0.7867500185966492\n",
            "min validation loss 2.223766803741455\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0030548316426575184\n",
            "last validation accuracy 0.7867500185966492\n",
            "last validation loss 2.223766803741455\n",
            "================================================================================\n",
            "Number of parameters = 28000, 35 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[322   0  16   1   5  17   6   3   0   0]\n",
            " [  0 418   4   9   1   0   4   5   9   0]\n",
            " [ 10  15 332  11   3   2   6  20  19   0]\n",
            " [  5   4  15 307   2  40   1  17  12   5]\n",
            " [  8   7   3   1 330   1  10  17  11  30]\n",
            " [ 23   1   5  22  14 255  15   3  23  11]\n",
            " [ 24   4  22   0  10  17 291   4   6   0]\n",
            " [  7   9  10  13  11   0   3 325   5  28]\n",
            " [  6  18   9  25   6  25   5   8 263  19]\n",
            " [  6   4   1  14  24   5   3  23   7 304]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_6 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 35)                27475     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                360       \n",
            "=================================================================\n",
            "Total params: 27,835\n",
            "Trainable params: 27,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0029986086301505566\n",
            "max validation accuracy 0.7867500185966492\n",
            "min validation loss 2.2293648719787598\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0029986086301505566\n",
            "last validation accuracy 0.7867500185966492\n",
            "last validation loss 2.2293648719787598\n",
            "================================================================================\n",
            "Number of parameters = 32000, 40 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[324   0  16   1   5  17   6   1   0   0]\n",
            " [  0 417   5   9   1   0   4   5   9   0]\n",
            " [ 11  14 329  11   3   3   7  20  20   0]\n",
            " [  7   4  14 305   2  41   1  16  12   6]\n",
            " [  8   7   4   1 327   0  12  15  11  33]\n",
            " [ 21   1   4  20  14 262  15   3  21  11]\n",
            " [ 26   4  21   0   9  17 293   3   5   0]\n",
            " [  7   9  10  14  11   1   3 323   5  28]\n",
            " [  6  16   9  25   7  27   6   8 261  19]\n",
            " [  7   4   1  13  24   6   3  18   7 308]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_7 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 40)                31400     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                410       \n",
            "=================================================================\n",
            "Total params: 31,810\n",
            "Trainable params: 31,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002937662648037076\n",
            "max validation accuracy 0.7872499823570251\n",
            "min validation loss 2.223114013671875\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002937662648037076\n",
            "last validation accuracy 0.7872499823570251\n",
            "last validation loss 2.223114013671875\n",
            "================================================================================\n",
            "Number of parameters = 34000, 42 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  18   1   4  17   6   1   0   0]\n",
            " [  0 417   5   9   1   0   4   5   9   0]\n",
            " [ 11  15 330  11   3   3   6  20  19   0]\n",
            " [  5   4  15 306   2  40   1  18  12   5]\n",
            " [  8   6   4   1 326   1  11  15  12  34]\n",
            " [ 21   1   4  21  14 261  15   3  21  11]\n",
            " [ 25   4  21   0   9  17 292   4   6   0]\n",
            " [  7   9  10  14  11   0   3 324   5  28]\n",
            " [  6  18   9  24   6  27   5   8 262  19]\n",
            " [  6   4   1  14  23   5   3  19   7 309]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 42)                32970     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                430       \n",
            "=================================================================\n",
            "Total params: 33,400\n",
            "Trainable params: 33,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.00292904837988317\n",
            "max validation accuracy 0.7875000238418579\n",
            "min validation loss 2.2258338928222656\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.00292904837988317\n",
            "last validation accuracy 0.7875000238418579\n",
            "last validation loss 2.2258338928222656\n",
            "================================================================================\n",
            "Number of parameters = 36000, 45 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[322   0  18   1   5  17   6   1   0   0]\n",
            " [  0 419   4   9   1   0   4   4   9   0]\n",
            " [ 10  15 331  11   3   3   6  20  19   0]\n",
            " [  5   4  15 307   2  40   1  17  12   5]\n",
            " [  8   7   3   1 328   1  11  16  11  32]\n",
            " [ 21   1   4  21  14 260  15   3  22  11]\n",
            " [ 24   4  22   0   8  17 293   4   6   0]\n",
            " [  6   9   9  14  11   1   4 324   5  28]\n",
            " [  6  17   7  24   6  27   5   8 265  19]\n",
            " [  6   4   1  14  23   5   3  19   7 309]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_9 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 45)                35325     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                460       \n",
            "=================================================================\n",
            "Total params: 35,785\n",
            "Trainable params: 35,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002858635038137436\n",
            "max validation accuracy 0.7894999980926514\n",
            "min validation loss 2.2292540073394775\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002858635038137436\n",
            "last validation accuracy 0.7894999980926514\n",
            "last validation loss 2.2292540073394775\n",
            "================================================================================\n",
            "Number of parameters = 38000, 47 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[322   0  18   1   5  17   6   1   0   0]\n",
            " [  0 419   4   9   1   0   4   4   9   0]\n",
            " [ 10  15 331  11   3   2   7  20  19   0]\n",
            " [  5   4  15 306   2  40   1  18  12   5]\n",
            " [  8   7   4   1 329   1  10  15  11  32]\n",
            " [ 21   1   4  22  14 257  16   3  23  11]\n",
            " [ 24   4  22   0   8  17 293   4   6   0]\n",
            " [  6   9  11  14  11   0   4 323   5  28]\n",
            " [  6  17   7  25   6  25   5   8 266  19]\n",
            " [  6   4   1  14  23   5   3  19   7 309]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 47)                36895     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                480       \n",
            "=================================================================\n",
            "Total params: 37,375\n",
            "Trainable params: 37,375\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0028010685928165913\n",
            "max validation accuracy 0.7887499928474426\n",
            "min validation loss 2.2203612327575684\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0028010685928165913\n",
            "last validation accuracy 0.7887499928474426\n",
            "last validation loss 2.2203612327575684\n",
            "================================================================================\n",
            "Number of parameters = 40000, 50 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  17   1   5  17   6   1   0   0]\n",
            " [  0 418   5   9   1   0   4   4   9   0]\n",
            " [ 11  14 330  11   3   3   6  20  20   0]\n",
            " [  5   4  15 307   2  40   1  17  12   5]\n",
            " [  8   7   3   1 328   1  11  16  11  32]\n",
            " [ 21   1   4  21  14 261  15   3  21  11]\n",
            " [ 25   4  21   0   8  17 293   4   6   0]\n",
            " [  6   9  10  14  11   1   4 323   5  28]\n",
            " [  6  15   8  24   7  27   5   8 265  19]\n",
            " [  7   4   1  14  23   5   3  20   7 307]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_11 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 39,760\n",
            "Trainable params: 39,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002793682739138603\n",
            "max validation accuracy 0.7887499928474426\n",
            "min validation loss 2.231839418411255\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002793682739138603\n",
            "last validation accuracy 0.7887499928474426\n",
            "last validation loss 2.231839418411255\n",
            "================================================================================\n",
            "Number of parameters = 42000, 52 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  16   1   5  17   6   2   0   0]\n",
            " [  0 419   3   9   1   0   4   5   9   0]\n",
            " [ 11  15 329  11   3   3   7  20  19   0]\n",
            " [  5   4  14 304   2  41   1  19  12   6]\n",
            " [  8   7   3   1 329   1  10  16  11  32]\n",
            " [ 21   1   4  20  14 262  15   3  21  11]\n",
            " [ 25   4  21   0   8  17 293   4   6   0]\n",
            " [  6   9   9  14  11   1   4 324   5  28]\n",
            " [  6  17   7  24   6  27   5   8 265  19]\n",
            " [  6   4   1  14  23   5   3  21   7 307]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 52)                40820     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                530       \n",
            "=================================================================\n",
            "Total params: 41,350\n",
            "Trainable params: 41,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0027400441467761993\n",
            "max validation accuracy 0.7887499928474426\n",
            "min validation loss 2.226696729660034\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0027400441467761993\n",
            "last validation accuracy 0.7887499928474426\n",
            "last validation loss 2.226696729660034\n",
            "================================================================================\n",
            "Number of parameters = 46000, 57 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  18   1   4  17   6   1   0   0]\n",
            " [  0 417   5   9   1   0   4   5   9   0]\n",
            " [ 11  15 329  11   3   3   7  20  19   0]\n",
            " [  5   4  15 306   2  41   1  17  12   5]\n",
            " [  8   7   3   1 328   1  12  16  11  31]\n",
            " [ 21   1   4  21  14 260  16   3  21  11]\n",
            " [ 25   4  21   0   8  17 293   4   6   0]\n",
            " [  6   9  10  14  11   0   4 325   5  27]\n",
            " [  6  16   9  24   7  27   5   8 263  19]\n",
            " [  6   4   1  14  23   5   3  22   7 306]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_13 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 57)                44745     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                580       \n",
            "=================================================================\n",
            "Total params: 45,325\n",
            "Trainable params: 45,325\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0027094718534499407\n",
            "max validation accuracy 0.7875000238418579\n",
            "min validation loss 2.2389907836914062\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0027094718534499407\n",
            "last validation accuracy 0.7875000238418579\n",
            "last validation loss 2.2389907836914062\n",
            "================================================================================\n",
            "Number of parameters = 50000, 62 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[324   0  17   1   4  17   6   1   0   0]\n",
            " [  0 416   5   9   1   0   4   5  10   0]\n",
            " [ 11  14 329  11   3   3   7  20  20   0]\n",
            " [  6   4  14 306   2  41   1  17  12   5]\n",
            " [  8   7   5   1 325   0  13  16  11  32]\n",
            " [ 21   1   4  20  14 262  15   3  21  11]\n",
            " [ 25   4  21   0   8  17 293   4   6   0]\n",
            " [  6   9   9  14  11   1   4 324   5  28]\n",
            " [  6  15   9  24   6  27   6   8 264  19]\n",
            " [  6   4   1  14  23   5   3  19   7 309]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_14 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 62)                48670     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                630       \n",
            "=================================================================\n",
            "Total params: 49,300\n",
            "Trainable params: 49,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0026987623423337936\n",
            "max validation accuracy 0.7879999876022339\n",
            "min validation loss 2.2396466732025146\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0026987623423337936\n",
            "last validation accuracy 0.7879999876022339\n",
            "last validation loss 2.2396466732025146\n",
            "================================================================================\n",
            "Number of parameters = 80000, 100 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[320   0  19   1   5  17   6   1   1   0]\n",
            " [  0 419   3   9   1   0   4   4  10   0]\n",
            " [ 10  16 326  12   3   3   9  20  19   0]\n",
            " [  5   4  15 307   2  42   0  17  11   5]\n",
            " [  8   6   3   1 326   1  12  17  12  32]\n",
            " [ 22   1   4  23  14 258  14   3  23  10]\n",
            " [ 24   4  22   0   7  17 292   5   7   0]\n",
            " [  6  10   9  14  13   1   4 325   5  24]\n",
            " [  6  18   6  24   6  27   6   8 264  19]\n",
            " [  6   4   1  14  23   5   3  22   8 305]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_15 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002962975762784481\n",
            "max validation accuracy 0.7854999899864197\n",
            "min validation loss 2.24003005027771\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002962975762784481\n",
            "last validation accuracy 0.7854999899864197\n",
            "last validation loss 2.24003005027771\n",
            "================================================================================\n",
            "Number of parameters = 150000, 188 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0  16   1   5  16   6   2   1   0]\n",
            " [  0 419   3   9   1   0   4   4  10   0]\n",
            " [ 11  14 326  15   3   2   7  20  20   0]\n",
            " [  5   4  13 306   2  40   1  20  12   5]\n",
            " [  9   6   3   1 329   1  11  15  10  33]\n",
            " [ 23   1   4  19  15 260  13   3  22  12]\n",
            " [ 26   4  21   0   9  16 291   4   7   0]\n",
            " [  7   9   9  14  12   1   3 325   5  26]\n",
            " [  7  16   8  24   6  26   6   8 263  20]\n",
            " [  7   4   1  13  23   5   3  20   7 308]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_16 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 188)               147580    \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                1890      \n",
            "=================================================================\n",
            "Total params: 149,470\n",
            "Trainable params: 149,470\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003435100894421339\n",
            "max validation accuracy 0.7875000238418579\n",
            "min validation loss 2.2540104389190674\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003435100894421339\n",
            "last validation accuracy 0.7875000238418579\n",
            "last validation loss 2.2540104389190674\n",
            "================================================================================\n",
            "Number of parameters = 300000, 377 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 1\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[322   0  16   1   5  17   6   2   1   0]\n",
            " [  0 421   3   9   1   0   4   3   9   0]\n",
            " [ 10  14 328  16   3   2   7  19  17   2]\n",
            " [  6   3  14 308   2  40   1  16  13   5]\n",
            " [  9   8   6   1 332   1  11  11   9  30]\n",
            " [ 21   1   3  20  15 263  13   3  21  12]\n",
            " [ 26   4  19   0   9  19 289   4   8   0]\n",
            " [  8  10  11  14  12   1   3 321   4  27]\n",
            " [  7  15   6  22   7  26   6   7 268  20]\n",
            " [  6   4   1  14  23   5   3  19   7 309]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_17 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 377)               295945    \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                3780      \n",
            "=================================================================\n",
            "Total params: 299,725\n",
            "Trainable params: 299,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002941470593214035\n",
            "max validation accuracy 0.7902500033378601\n",
            "min validation loss 2.232588291168213\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002941470593214035\n",
            "last validation accuracy 0.7902500033378601\n",
            "last validation loss 2.239179849624634\n",
            "================================================================================\n",
            "Number of parameters = 800000, 1006 hidden layer neurons\n",
            "================================================================================\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 10\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[341   0  12   0   3   6   5   1   0   2]\n",
            " [  0 424   5   5   1   2   3   3   7   0]\n",
            " [  9  10 353   6   2   0   4  16  16   2]\n",
            " [  5   4  15 320   0  34   2  16   8   4]\n",
            " [  3   3   6   1 352   1  10   4   7  31]\n",
            " [ 19   1   5  22  12 278   8   4  13  10]\n",
            " [ 17   4  21   0   6  13 312   1   4   0]\n",
            " [  1   8  10  13   8   2   3 332   5  29]\n",
            " [  6  17   2  24   7  17   5   7 285  14]\n",
            " [  5   5   2  11  21   6   2  18   8 313]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_18 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1006)              789710    \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                10070     \n",
            "=================================================================\n",
            "Total params: 799,780\n",
            "Trainable params: 799,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0005921097472310066\n",
            "max validation accuracy 0.827750027179718\n",
            "min validation loss 2.0242621898651123\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0005921097472310066\n",
            "last validation accuracy 0.8274999856948853\n",
            "last validation loss 2.0256028175354004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8413bbcf50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "qmP28-T8sBMg",
        "outputId": "d0640687-d9d8-4f53-f1cb-b6d0f6eda2ec"
      },
      "source": [
        "# plot errors over number of parameters\n",
        "plt.title('Training and validation error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['val_accuracy'][-1] for i in history_logs], color='blue', label='val_error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['accuracy'][-1] for i in history_logs], color='orange', label='training error')\n",
        "plt.xlabel('Number of parameters N(*10^3)')\n",
        "plt.ylabel('Error')\n",
        "# locs = [0, 150, 350, 550, 700, 800]\n",
        "# ticks = [3, 10, 40, 100, 300, 800]\n",
        "locs = [0, 350, 450, 550, 700, 800]\n",
        "ticks = [3, 6, 8, 10, 300, 800]\n",
        "plt.xticks(locs, ticks)\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f83f9b9b310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOaMYivifD5a",
        "outputId": "50e62a41-1d12-455b-d2bf-39ce2d25ed17"
      },
      "source": [
        "# full MNIST\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "def lr_decay(epoch, lr):\n",
        "    return lr * 0.9**(epoch//500)\n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
        "\n",
        "# For networks smaller than the interpolation threshold, training is stopped after classification error reached zero or 6000 epochs,\n",
        "class CustomCallback_epoch(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      if logs[\"accuracy\"]==1:\n",
        "        self.model.stop_training = True\n",
        "        print('STOPPING EARLY AFTER INTERPOLATING AT EPOCH %d' %epoch)\n",
        "        print('INTERPOLATION THRESHOLD REACHED')\n",
        "\n",
        "history_logs_2 = []\n",
        "saved_weights_2 = []\n",
        "\n",
        "num_parameters = [i*1000 for i in [3, 6, 9, 12, 24, 28, 32, 34, 36, 38, 40, 42, 46, 50, 80, 150, 300, 800]]\n",
        "hidden_sizes = [(N-10)//795 for N in num_parameters]\n",
        "for N in num_parameters:\n",
        "  print('='*80)\n",
        "  print('Number of parameters = %d, %d hidden layer neurons' %(N, (N-10)//795)) \n",
        "  print('='*80)\n",
        "\n",
        "  # P = (d+1)·H+(H+1)·K = 785H+10H+10 = 795H+10 --> H = (P-10)/795\n",
        "  num_nodes = (N-10)//795\n",
        "  # The remaining weights are initialized with normally distributed random numbers (mean 0 and variance 0.01). The smallest network is initialized using standard Glorotuniform distribution [19].\n",
        "  normal_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01**0.5)\n",
        "  glorot_initializer = tf.keras.initializers.GlorotUniform()  \n",
        "  # if this is the first model (smallest network) use standard Glorotuniform, otherwise use random normal\n",
        "  initializer = normal_initializer if saved_weights_2 else glorot_initializer\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(num_nodes, activation='relu', kernel_initializer=initializer, bias_initializer=initializer),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer, bias_initializer=initializer)\n",
        "  ])\n",
        "\n",
        "  # paper used SGD with standard momentum (parameter value 0.95)\n",
        "  opt = tf.keras.optimizers.SGD(momentum=0.95)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  # print(model.weights[0].shape)\n",
        "  # print(model.weights[1].shape)\n",
        "  # # print(model.weights[1])\n",
        "  # print(model.weights[2].shape)\n",
        "  # # print(model.weights[2])\n",
        "  # print(model.weights[3].shape)\n",
        "  # # print(model.weights[3])\n",
        "\n",
        "  # from paper: To train a larger network with H2 > H1 hidden units, we initialize the first H1 hidden units of the larger network to the weights learned in the smaller network.  \n",
        "  # equivalently, here we expand saved weight with H1 units from prev model with randomly initialized weight for the new hidden units from the new model, then re-assign the combined weights to the new model\n",
        "  if saved_weights_2: \n",
        "    prev_weights = saved_weights_2[-1]\n",
        "    tf.compat.v1.assign(model.weights[0], tf.concat((prev_weights[0], model.weights[0][:, prev_weights[0].shape[1]:]), axis=1))\n",
        "    tf.compat.v1.assign(model.weights[1], tf.concat((prev_weights[1], model.weights[1][prev_weights[1].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[2], tf.concat((prev_weights[2], model.weights[2][prev_weights[2].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[3], prev_weights[3])\n",
        "\n",
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs,\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "\n",
        "  interpolated = history_logs_2 and max([h[1].history['loss'] for h in history_logs_2])[0] == 1.0\n",
        "  \n",
        "  # The expected interpolation threshold: paper observed it at n · K = 4000 * 10 = 40000\n",
        "  # interpolated = N >= 40000\n",
        "\n",
        "  if not interpolated:\n",
        "    history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), verbose=0, callbacks=[scheduler])\n",
        "  else:\n",
        "    history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), verbose=0)\n",
        "  \n",
        "  saved_weights.append(model.weights)\n",
        "\n",
        "  history_logs_2.append((N, history))\n",
        "  print(tf.math.confusion_matrix(y_test, tf.argmax(model.predict(x_test), axis=1)))\n",
        "  model.summary()\n",
        "  print('max training accuracy', max(history.history['accuracy']))\n",
        "  print('min training loss', min(history.history['loss']))\n",
        "  print('max validation accuracy', max(history.history['val_accuracy']))\n",
        "  print('min validation loss', min(history.history['val_loss']))\n",
        "  print()\n",
        "  print('last training accuracy', history.history['accuracy'][-1])\n",
        "  print('last training loss', history.history['loss'][-1])\n",
        "  print('last validation accuracy', history.history['val_accuracy'][-1])\n",
        "  print('last validation loss', history.history['val_loss'][-1])\n",
        "  \n",
        "# plot errors over number of parameters\n",
        "plt.title('Training and validation error')\n",
        "plt.plot([i[0]//1000 for i in history_logs_2], [1-i[1].history['val_accuracy'][-1] for i in history_logs_2], color='blue', label='val_error')\n",
        "plt.plot([i[0]//1000 for i in history_logs_2], [1-i[1].history['accuracy'][-1] for i in history_logs_2], color='orange', label='training error')\n",
        "plt.xlabel('Number of parameters N(*10^3)')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Number of parameters = 3000, 3 hidden layer neurons\n",
            "================================================================================\n",
            "tf.Tensor(\n",
            "[[ 806    0    0    7    2  153   10    1    1    0]\n",
            " [   0 1079    9    5    4    1    4    0   32    1]\n",
            " [   3   20  724  168   11   11   29    5   60    1]\n",
            " [   5    3   28  789    4   51    3   84   40    3]\n",
            " [   0    2    0    0  929    3   17    6    8   17]\n",
            " [  27    0    6   44   37  613   48   40   68    9]\n",
            " [   6    0    2    0   10   24  902    0   14    0]\n",
            " [   2   26    1   24   12    4    0  940    3   16]\n",
            " [   5   27    9   43  211  131   62   20  459    7]\n",
            " [   2    1    0    4  284   36    2  223    4  453]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_20 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 3)                 2355      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10)                40        \n",
            "=================================================================\n",
            "Total params: 2,395\n",
            "Trainable params: 2,395\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.8008166551589966\n",
            "min training loss 0.6429833173751831\n",
            "max validation accuracy 0.8137000203132629\n",
            "min validation loss 0.6246053576469421\n",
            "\n",
            "last training accuracy 0.7994499802589417\n",
            "last training loss 0.6466578245162964\n",
            "last validation accuracy 0.7694000005722046\n",
            "last validation loss 0.7171195149421692\n",
            "================================================================================\n",
            "Number of parameters = 6000, 7 hidden layer neurons\n",
            "================================================================================\n",
            "tf.Tensor(\n",
            "[[ 949    0    0    5    1    4   15    2    4    0]\n",
            " [   0 1092    6   15    1    2    3    0   15    1]\n",
            " [  23   12  853   67   12    0   16   10   37    2]\n",
            " [   1    4   25  918    2   34    1    8    9    8]\n",
            " [   3    5    1    0  902    1   26    3   10   31]\n",
            " [  22    2    3  125   10  653   22    1   38   16]\n",
            " [  25    4    3    0   12   14  892    0    8    0]\n",
            " [   5   16   14   25   14    1    0  887    0   66]\n",
            " [  14   14    4   35   14   29   20    3  804   37]\n",
            " [  10    3    1   10   40    7    0   16   13  909]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_21 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 7)                 5495      \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 10)                80        \n",
            "=================================================================\n",
            "Total params: 5,575\n",
            "Trainable params: 5,575\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.8967499732971191\n",
            "min training loss 0.3614636957645416\n",
            "max validation accuracy 0.897599995136261\n",
            "min validation loss 0.37404894828796387\n",
            "\n",
            "last training accuracy 0.8930666446685791\n",
            "last training loss 0.3726237714290619\n",
            "last validation accuracy 0.8859000205993652\n",
            "last validation loss 0.40797269344329834\n",
            "================================================================================\n",
            "Number of parameters = 9000, 11 hidden layer neurons\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EVV7tFotq-d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}