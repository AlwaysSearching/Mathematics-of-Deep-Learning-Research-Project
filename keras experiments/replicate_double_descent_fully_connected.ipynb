{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "replicate_double_descent_fully_connected.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komPxXzy6oTT",
        "outputId": "511e7793-7c2d-4747-def1-a1755c62ca4d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.layers import Dense, Flatten \n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYkDDKhP6ozO",
        "outputId": "bd9e301a-a6e1-4a5a-aefd-d2ae7b2da9d1"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqNW9NH6rvs"
      },
      "source": [
        "# paper's fully connected model learned on a subset of MNIST (n = 4000, d = 784, K = 10 classes)\n",
        "x_train, y_train = x_train[:4000], y_train[:4000]\n",
        "x_test, y_test = x_test[:4000], y_test[:4000]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y6-hXm1t6vf_",
        "outputId": "627c221f-dfa8-4487-f89d-6a13f2a9784f"
      },
      "source": [
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "def lr_decay(epoch, lr):\n",
        "    return lr * 0.9**(epoch//500)\n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
        "\n",
        "# For networks smaller than the interpolation threshold, training is stopped after classification error reached zero or 6000 epochs,\n",
        "class CustomCallback_epoch(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      if logs[\"accuracy\"]==1:\n",
        "        self.model.stop_training = True\n",
        "        print('STOPPING EARLY AFTER INTERPOLATING AT EPOCH %d' %epoch)\n",
        "        print('INTERPOLATION THRESHOLD REACHED')\n",
        "\n",
        "history_logs = []\n",
        "saved_weights = []\n",
        "\n",
        "num_parameters = [i*1000 for i in [3, 6, 9, 12, 24, 28, 32, 34, 36, 38, 40, 42, 46, 50, 80, 150, 300, 800]]\n",
        "hidden_sizes = [(N-10)//795 for N in num_parameters]\n",
        "for N in num_parameters:\n",
        "  print('='*80)\n",
        "  print('Number of parameters = %d, %d hidden layer neurons' %(N, (N-10)//795)) \n",
        "  print('='*80)\n",
        "\n",
        "  # P = (d+1)·H+(H+1)·K = 785H+10H+10 = 795H+10 --> H = (P-10)/795\n",
        "  num_nodes = (N-10)//795\n",
        "  # The remaining weights are initialized with normally distributed random numbers (mean 0 and variance 0.01). The smallest network is initialized using standard Glorotuniform distribution [19].\n",
        "  normal_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01**0.5)\n",
        "  glorot_initializer = tf.keras.initializers.GlorotUniform()  \n",
        "  # if this is the first model (smallest network) use standard Glorotuniform, otherwise use random normal\n",
        "  initializer = normal_initializer if saved_weights else glorot_initializer\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(num_nodes, activation='relu', kernel_initializer=initializer, bias_initializer=initializer),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer, bias_initializer=initializer)\n",
        "  ])\n",
        "\n",
        "  # paper used SGD with standard momentum (parameter value 0.95)\n",
        "  opt = tf.keras.optimizers.SGD(momentum=0.95)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  # print(model.weights[0].shape)\n",
        "  # print(model.weights[1].shape)\n",
        "  # # print(model.weights[1])\n",
        "  # print(model.weights[2].shape)\n",
        "  # # print(model.weights[2])\n",
        "  # print(model.weights[3].shape)\n",
        "  # # print(model.weights[3])\n",
        "\n",
        "  # from paper: To train a larger network with H2 > H1 hidden units, we initialize the first H1 hidden units of the larger network to the weights learned in the smaller network.  \n",
        "  # equivalently, here we expand saved weight with H1 units from prev model with randomly initialized weight for the new hidden units from the new model, then re-assign the combined weights to the new model\n",
        "  if saved_weights: \n",
        "    prev_weights = saved_weights[-1]\n",
        "    tf.compat.v1.assign(model.weights[0], tf.concat((prev_weights[0], model.weights[0][:, prev_weights[0].shape[1]:]), axis=1))\n",
        "    tf.compat.v1.assign(model.weights[1], tf.concat((prev_weights[1], model.weights[1][prev_weights[1].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[2], tf.concat((prev_weights[2], model.weights[2][prev_weights[2].shape[0]:]), axis=0))\n",
        "    tf.compat.v1.assign(model.weights[3], prev_weights[3])\n",
        "\n",
        "# For networks smaller than the interpolation threshold, we decay the step size by 10% after each of 500 epochs,\n",
        "# For these networks, training is stopped after classification error reached zero or 6000 epochs, whichever happens earlier. For networks larger than interpolation threshold, fixed step size is used, and training is stopped after 6000 epochs.\n",
        "\n",
        "  # The expected interpolation threshold: paper observed it at n · K = 4000 * 10 = 40000\n",
        "  interpolated = history_logs and max([h[1].history['accuracy'] for h in history_logs])[0] == 1.0\n",
        "  if not interpolated:\n",
        "    history = model.fit(x_train, y_train, epochs=6000, validation_data=(x_test, y_test), verbose=0, callbacks=[CustomCallback_epoch(), scheduler])\n",
        "  else:\n",
        "    history = model.fit(x_train, y_train, epochs=6000, validation_data=(x_test, y_test), verbose=0)\n",
        "  \n",
        "  saved_weights.append(model.weights)\n",
        "\n",
        "  history_logs.append((N, history))\n",
        "  print(tf.math.confusion_matrix(y_test, tf.argmax(model.predict(x_test), axis=1)))\n",
        "  model.summary()\n",
        "  print('max training accuracy', max(history.history['accuracy']))\n",
        "  print('min training loss', min(history.history['loss']))\n",
        "  print('max validation accuracy', max(history.history['val_accuracy']))\n",
        "  print('min validation loss', min(history.history['val_loss']))\n",
        "  print()\n",
        "  print('last training accuracy', history.history['accuracy'][-1])\n",
        "  print('last training loss', history.history['loss'][-1])\n",
        "  print('last validation accuracy', history.history['val_accuracy'][-1])\n",
        "  print('last validation loss', history.history['val_loss'][-1])\n",
        "  \n",
        "# plot errors over number of parameters\n",
        "plt.title('Training and validation error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['val_accuracy'][-1] for i in history_logs], color='blue', label='val_error')\n",
        "plt.plot([i[0]//1000 for i in history_logs], [1-i[1].history['accuracy'][-1] for i in history_logs], color='orange', label='training error')\n",
        "plt.xlabel('Number of parameters N(*10^3)')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Number of parameters = 3000, 3 hidden layer neurons\n",
            "================================================================================\n",
            "tf.Tensor(\n",
            "[[  0   8  13   6   0   0 332   0  10   1]\n",
            " [  0 402   0   2  17   0  14   0  13   2]\n",
            " [  0  23   6   7   8   0 347   1  18   8]\n",
            " [  0  64  15  22  11   0 248   4  33  11]\n",
            " [  0 110   0   0 153   0  10  19   6 120]\n",
            " [  0  57  14  29   5   0 220   1  40   6]\n",
            " [  0  12   5   5   3   0 341   0  11   1]\n",
            " [  0  30   0   1  32   0   4 239   0 105]\n",
            " [  0 100  19  33  12   0 147   2  62   9]\n",
            " [  0  41   2   1  64   0   5  86   4 188]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_67 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_134 (Dense)            (None, 3)                 2355      \n",
            "_________________________________________________________________\n",
            "dense_135 (Dense)            (None, 10)                40        \n",
            "=================================================================\n",
            "Total params: 2,395\n",
            "Trainable params: 2,395\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.3930000066757202\n",
            "min training loss 1.4829939603805542\n",
            "max validation accuracy 0.35324999690055847\n",
            "min validation loss 1.7630982398986816\n",
            "\n",
            "last training accuracy 0.3747499883174896\n",
            "last training loss 1.4955180883407593\n",
            "last validation accuracy 0.35324999690055847\n",
            "last validation loss 1.8550288677215576\n",
            "================================================================================\n",
            "Number of parameters = 6000, 7 hidden layer neurons\n",
            "================================================================================\n",
            "[0.1899999976158142, 0.2605000138282776, 0.26524999737739563, 0.2775000035762787, 0.28700000047683716, 0.2982499897480011, 0.2917500138282776, 0.2874999940395355, 0.28824999928474426, 0.2952499985694885, 0.28700000047683716, 0.29624998569488525, 0.31299999356269836, 0.34200000762939453, 0.351749986410141, 0.35324999690055847, 0.3319999873638153, 0.3434999883174896, 0.3472500145435333, 0.3400000035762787, 0.33899998664855957, 0.3412500023841858, 0.3552500009536743, 0.34200000762939453, 0.3619999885559082, 0.34599998593330383, 0.36024999618530273, 0.3607499897480011, 0.3527500033378601, 0.35725000500679016, 0.35324999690055847, 0.3644999861717224, 0.36000001430511475, 0.3630000054836273, 0.3577499985694885, 0.3617500066757202, 0.3527500033378601, 0.36274999380111694, 0.3659999966621399, 0.3630000054836273, 0.3647499978542328, 0.359499990940094, 0.37024998664855957, 0.36649999022483826, 0.36274999380111694, 0.35324999690055847, 0.34325000643730164, 0.3815000057220459, 0.36625000834465027, 0.3762499988079071, 0.3720000088214874, 0.36800000071525574, 0.359250009059906, 0.36399999260902405, 0.3762499988079071, 0.37049999833106995, 0.36800000071525574, 0.38199999928474426, 0.37825000286102295, 0.37424999475479126, 0.3787499964237213, 0.3697499930858612, 0.382750004529953, 0.3817499876022339, 0.3682500123977661, 0.3787499964237213, 0.3712500035762787, 0.3714999854564667, 0.36899998784065247, 0.37575000524520874, 0.38100001215934753, 0.3785000145435333, 0.37174999713897705, 0.36774998903274536, 0.3722499907016754, 0.38850000500679016, 0.36625000834465027, 0.38199999928474426, 0.3787499964237213, 0.37400001287460327, 0.3815000057220459, 0.3852500021457672, 0.3877499997615814, 0.3747499883174896, 0.3785000145435333, 0.3747499883174896, 0.3855000138282776, 0.38725000619888306, 0.375, 0.3774999976158142, 0.38199999928474426, 0.38749998807907104, 0.3815000057220459, 0.3892500102519989, 0.3930000066757202, 0.3855000138282776, 0.38374999165534973, 0.39250001311302185, 0.3894999921321869, 0.3747499883174896] False False\n",
            "tf.Tensor(\n",
            "[[316   1   7   3   1  28   9   3   2   0]\n",
            " [  0 412  12   2   1   0   4   1  16   2]\n",
            " [  6   4 338  18   4   1   5   7  29   6]\n",
            " [  6   2  25 277   1  43   1   8  35  10]\n",
            " [  0   1   3   3 344   7  24   1   5  30]\n",
            " [ 17   0   3  11   4 276   6   6  37  12]\n",
            " [ 10   1  29   0  12  24 297   0   5   0]\n",
            " [  0  28   4  22   5   3   0 294   1  54]\n",
            " [  5   7   8  16   6  35   6   1 283  17]\n",
            " [  1   3   3   9  36   5   4  10  11 309]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_68 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_136 (Dense)            (None, 7)                 5495      \n",
            "_________________________________________________________________\n",
            "dense_137 (Dense)            (None, 10)                80        \n",
            "=================================================================\n",
            "Total params: 5,575\n",
            "Trainable params: 5,575\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.9792500138282776\n",
            "min training loss 0.09262977540493011\n",
            "max validation accuracy 0.8072500228881836\n",
            "min validation loss 0.8063564896583557\n",
            "\n",
            "last training accuracy 0.96875\n",
            "last training loss 0.11002751439809799\n",
            "last validation accuracy 0.7864999771118164\n",
            "last validation loss 1.479798674583435\n",
            "================================================================================\n",
            "Number of parameters = 9000, 11 hidden layer neurons\n",
            "================================================================================\n",
            "[0.5107499957084656, 0.78125, 0.8414999842643738, 0.8619999885559082, 0.8799999952316284, 0.8880000114440918, 0.8992499709129333, 0.9012500047683716, 0.8997499942779541, 0.9027500152587891, 0.9110000133514404, 0.9057499766349792, 0.9122499823570251, 0.9162499904632568, 0.9142500162124634, 0.9132500290870667, 0.9225000143051147, 0.9237499833106995, 0.9229999780654907, 0.9244999885559082, 0.921500027179718, 0.9294999837875366, 0.9325000047683716, 0.9312499761581421, 0.9340000152587891, 0.9362499713897705, 0.940750002861023, 0.9362499713897705, 0.9275000095367432, 0.925000011920929, 0.9380000233650208, 0.9434999823570251, 0.9455000162124634, 0.9419999718666077, 0.9417499899864197, 0.9415000081062317, 0.9484999775886536, 0.9322500228881836, 0.9399999976158142, 0.9449999928474426, 0.9497500061988831, 0.9462500214576721, 0.9440000057220459, 0.9465000033378601, 0.9482499957084656, 0.9487500190734863, 0.9440000057220459, 0.9427499771118164, 0.9492499828338623, 0.9467499852180481, 0.9552500247955322, 0.9574999809265137, 0.9524999856948853, 0.9462500214576721, 0.9559999704360962, 0.9514999985694885, 0.9487500190734863, 0.949999988079071, 0.956250011920929, 0.9567499756813049, 0.9542499780654907, 0.9580000042915344, 0.9622499942779541, 0.9627500176429749, 0.968500018119812, 0.9620000123977661, 0.9647499918937683, 0.9627500176429749, 0.9632499814033508, 0.9567499756813049, 0.9642500281333923, 0.9649999737739563, 0.9647499918937683, 0.9679999947547913, 0.9620000123977661, 0.9672499895095825, 0.9632499814033508, 0.9697499871253967, 0.9664999842643738, 0.9674999713897705, 0.9645000100135803, 0.9710000157356262, 0.9735000133514404, 0.9727500081062317, 0.9727500081062317, 0.9737499952316284, 0.9700000286102295, 0.965499997138977, 0.968500018119812, 0.9767500162124634, 0.9752500057220459, 0.9747499823570251, 0.9752500057220459, 0.968999981880188, 0.9732499718666077, 0.9777500033378601, 0.9707499742507935, 0.9792500138282776, 0.9737499952316284, 0.96875] False False\n",
            "tf.Tensor(\n",
            "[[328   0   8   2   3  11   6   6   3   3]\n",
            " [  0 420   5   6   3   0   5   2   7   2]\n",
            " [  7   2 333  18   1   2   9  11  26   9]\n",
            " [  4   1  15 315   2  36   1  10  17   7]\n",
            " [  0   3   3   5 363   4  13   2   3  22]\n",
            " [ 10   1   1  12   7 287   5   8  24  17]\n",
            " [ 14   2  27   0  19  18 292   1   5   0]\n",
            " [  0  11   2  13   6   2   0 348   1  28]\n",
            " [  8   7  10  21  13  21   5   5 273  21]\n",
            " [  4   5   1  14  26   1   0  17   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_69 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 11)                8635      \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 10)                120       \n",
            "=================================================================\n",
            "Total params: 8,755\n",
            "Trainable params: 8,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 0.999750018119812\n",
            "min training loss 0.0040067033842206\n",
            "max validation accuracy 0.8207499980926514\n",
            "min validation loss 1.4749579429626465\n",
            "\n",
            "last training accuracy 0.9994999766349792\n",
            "last training loss 0.0040067033842206\n",
            "last validation accuracy 0.8192499876022339\n",
            "last validation loss 1.7564893960952759\n",
            "================================================================================\n",
            "Number of parameters = 12000, 15 hidden layer neurons\n",
            "================================================================================\n",
            "[0.9742500185966492, 0.981249988079071, 0.9794999957084656, 0.9794999957084656, 0.9695000052452087, 0.9722499847412109, 0.9800000190734863, 0.9802500009536743, 0.9825000166893005, 0.9877499938011169, 0.984749972820282, 0.9862499833106995, 0.9737499952316284, 0.972000002861023, 0.981249988079071, 0.9865000247955322, 0.9860000014305115, 0.9907500147819519, 0.9877499938011169, 0.9869999885559082, 0.9832500219345093, 0.9897500276565552, 0.9887499809265137, 0.9879999756813049, 0.9919999837875366, 0.9940000176429749, 0.9925000071525574, 0.9915000200271606, 0.9922500252723694, 0.9925000071525574, 0.9909999966621399, 0.9934999942779541, 0.9940000176429749, 0.9957500100135803, 0.9957500100135803, 0.996749997138977, 0.9972500205039978, 0.9965000152587891, 0.9972500205039978, 0.9975000023841858, 0.9972500205039978, 0.9975000023841858, 0.9977499842643738, 0.9977499842643738, 0.9975000023841858, 0.9975000023841858, 0.9984999895095825, 0.9980000257492065, 0.9982500076293945, 0.9982500076293945, 0.9982500076293945, 0.9984999895095825, 0.9984999895095825, 0.9984999895095825, 0.9984999895095825, 0.9984999895095825, 0.9987499713897705, 0.9984999895095825, 0.9982500076293945, 0.9984999895095825, 0.9984999895095825, 0.9987499713897705, 0.9987499713897705, 0.9987499713897705, 0.9987499713897705, 0.9987499713897705, 0.9987499713897705, 0.9987499713897705, 0.9987499713897705, 0.9990000128746033, 0.9992499947547913, 0.9990000128746033, 0.9992499947547913, 0.9992499947547913, 0.9990000128746033, 0.9990000128746033, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 0.9994999766349792, 0.999750018119812, 0.9994999766349792, 0.999750018119812, 0.999750018119812, 0.999750018119812, 0.999750018119812, 0.9994999766349792] False False\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 3\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   8   2   3  11   6   6   3   3]\n",
            " [  0 420   5   6   3   0   5   2   7   2]\n",
            " [  6   2 332  18   1   3   9  11  27   9]\n",
            " [  4   1  16 311   2  38   1  10  17   8]\n",
            " [  0   3   3   5 357   6  12   2   3  27]\n",
            " [ 10   1   1  12   7 288   5   8  23  17]\n",
            " [ 14   2  26   0  19  17 294   1   5   0]\n",
            " [  0  11   1  13   6   2   0 348   1  29]\n",
            " [  7   7  10  21  13  21   5   5 273  22]\n",
            " [  4   5   1  13  25   2   0  16   5 320]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_70 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 15)                11775     \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 10)                160       \n",
            "=================================================================\n",
            "Total params: 11,935\n",
            "Trainable params: 11,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0038379060570150614\n",
            "max validation accuracy 0.8190000057220459\n",
            "min validation loss 1.763914942741394\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0038379060570150614\n",
            "last validation accuracy 0.8177499771118164\n",
            "last validation loss 1.7731657028198242\n",
            "================================================================================\n",
            "Number of parameters = 24000, 30 hidden layer neurons\n",
            "================================================================================\n",
            "[0.9992499947547913, 0.9992499947547913, 0.9992499947547913, 1.0] False False\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 3\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   8   2   3  11   6   6   3   3]\n",
            " [  0 420   5   6   3   0   5   2   7   2]\n",
            " [  6   2 334  16   1   3   9  11  26  10]\n",
            " [  4   2  16 310   2  38   1  11  17   7]\n",
            " [  0   3   3   5 362   6  12   2   2  23]\n",
            " [ 10   1   1  12   7 287   5   9  25  15]\n",
            " [ 13   2  28   0  19  19 291   1   5   0]\n",
            " [  0  10   1  13   6   2   0 351   1  27]\n",
            " [  8   7  10  21  14  21   5   5 272  21]\n",
            " [  4   5   1  13  26   2   0  17   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_71 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 23,860\n",
            "Trainable params: 23,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003550606081262231\n",
            "max validation accuracy 0.8195000290870667\n",
            "min validation loss 1.7762928009033203\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003550606081262231\n",
            "last validation accuracy 0.8182500004768372\n",
            "last validation loss 1.7898063659667969\n",
            "================================================================================\n",
            "Number of parameters = 28000, 35 hidden layer neurons\n",
            "================================================================================\n",
            "[0.999750018119812, 0.999750018119812, 0.999750018119812, 1.0] False False\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 1\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[322   0   8   2   3  15   7   6   3   4]\n",
            " [  0 420   5   6   3   0   5   2   7   2]\n",
            " [  6   2 334  16   1   3   9  11  26  10]\n",
            " [  3   1  17 310   2  39   1  11  17   7]\n",
            " [  0   3   3   5 362   6  13   2   3  21]\n",
            " [ 10   1   1  12   7 286   5   9  25  16]\n",
            " [ 11   2  27   0  19  19 294   1   5   0]\n",
            " [  0  10   2  13   7   2   0 349   1  27]\n",
            " [  7   7  11  19  14  21   5   5 274  21]\n",
            " [  4   5   1  13  27   2   0  16   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_72 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 35)                27475     \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 10)                360       \n",
            "=================================================================\n",
            "Total params: 27,835\n",
            "Trainable params: 27,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0033896928653120995\n",
            "max validation accuracy 0.8190000057220459\n",
            "min validation loss 1.78583824634552\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0033896928653120995\n",
            "last validation accuracy 0.8172500133514404\n",
            "last validation loss 1.78583824634552\n",
            "================================================================================\n",
            "Number of parameters = 32000, 40 hidden layer neurons\n",
            "================================================================================\n",
            "[0.999750018119812, 1.0] False False\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[324   0   8   2   3  14   6   6   3   4]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 332  18   1   3   9  11  27   9]\n",
            " [  3   2  16 310   2  39   1  10  17   8]\n",
            " [  0   3   3   5 358   5  13   2   2  27]\n",
            " [ 10   1   0  11   8 285   5   8  27  17]\n",
            " [ 12   2  26   0  19  18 295   1   5   0]\n",
            " [  0  12   1  13   6   2   0 344   1  32]\n",
            " [  7   8   9  20  13  21   5   5 274  22]\n",
            " [  4   5   1  13  25   2   0  15   5 321]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_73 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 40)                31400     \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 10)                410       \n",
            "=================================================================\n",
            "Total params: 31,810\n",
            "Trainable params: 31,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003341963980346918\n",
            "max validation accuracy 0.8159999847412109\n",
            "min validation loss 1.795954942703247\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003341963980346918\n",
            "last validation accuracy 0.8159999847412109\n",
            "last validation loss 1.795954942703247\n",
            "================================================================================\n",
            "Number of parameters = 34000, 42 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[324   0   8   2   3  13   6   6   4   4]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 332  17   1   3   9  11  27  10]\n",
            " [  3   2  16 314   2  36   1  10  17   7]\n",
            " [  0   3   3   5 357   5  15   2   3  25]\n",
            " [ 11   1   1  11   7 284   5   8  27  17]\n",
            " [ 12   2  26   0  19  18 295   1   5   0]\n",
            " [  0  11   1  13   6   2   0 345   1  32]\n",
            " [  7   7  10  20  13  20   5   5 276  21]\n",
            " [  4   5   1  13  25   2   0  15   5 321]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_74 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 42)                32970     \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 10)                430       \n",
            "=================================================================\n",
            "Total params: 33,400\n",
            "Trainable params: 33,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0032726144418120384\n",
            "max validation accuracy 0.8172500133514404\n",
            "min validation loss 1.7873181104660034\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0032726144418120384\n",
            "last validation accuracy 0.8172500133514404\n",
            "last validation loss 1.7873181104660034\n",
            "================================================================================\n",
            "Number of parameters = 36000, 45 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   8   2   3  10   6   6   4   3]\n",
            " [  0 421   4   5   3   1   5   2   7   2]\n",
            " [  6   2 334  17   1   3   9  11  26   9]\n",
            " [  4   3  16 310   2  38   1  11  16   7]\n",
            " [  0   3   3   5 362   5  15   2   3  20]\n",
            " [ 11   1   1  11   7 284   5   9  27  16]\n",
            " [ 14   2  26   0  17  17 296   1   5   0]\n",
            " [  0  11   1  13   6   2   0 348   1  29]\n",
            " [  8   7  10  20  13  19   5   5 277  20]\n",
            " [  4   5   1  13  26   2   0  16   5 319]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_75 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 45)                35325     \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 10)                460       \n",
            "=================================================================\n",
            "Total params: 35,785\n",
            "Trainable params: 35,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003241667989641428\n",
            "max validation accuracy 0.8197500109672546\n",
            "min validation loss 1.7826858758926392\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003241667989641428\n",
            "last validation accuracy 0.8197500109672546\n",
            "last validation loss 1.7826858758926392\n",
            "================================================================================\n",
            "Number of parameters = 38000, 47 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[325   0   8   2   3  13   6   6   3   4]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 331  16   1   5   9  11  27  10]\n",
            " [  3   2  16 309   2  39   1  11  17   8]\n",
            " [  0   3   3   6 359   5  12   2   2  26]\n",
            " [ 11   1   0  12   8 284   5   9  26  16]\n",
            " [ 13   2  26   0  19  20 292   1   5   0]\n",
            " [  0  10   1  12   6   2   0 351   1  28]\n",
            " [  7   7  10  21  13  21   5   5 273  22]\n",
            " [  4   5   1  13  25   2   0  16   5 320]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_76 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 47)                36895     \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 10)                480       \n",
            "=================================================================\n",
            "Total params: 37,375\n",
            "Trainable params: 37,375\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0031091284472495317\n",
            "max validation accuracy 0.8162500262260437\n",
            "min validation loss 1.8040722608566284\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0031091284472495317\n",
            "last validation accuracy 0.8162500262260437\n",
            "last validation loss 1.8040722608566284\n",
            "================================================================================\n",
            "Number of parameters = 40000, 50 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0   8   2   3  11   6   6   4   3]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 334  15   1   4   9  11  26  10]\n",
            " [  4   3  16 309   2  38   1  11  16   8]\n",
            " [  0   3   3   6 361   4  15   2   3  21]\n",
            " [ 11   1   1  11   7 284   5   9  27  16]\n",
            " [ 14   2  26   0  17  17 296   1   5   0]\n",
            " [  0  11   1  12   6   2   0 351   1  27]\n",
            " [  8   7  11  20  14  20   6   5 273  20]\n",
            " [  4   5   1  13  26   2   0  17   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_77 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 39,760\n",
            "Trainable params: 39,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003131310222670436\n",
            "max validation accuracy 0.8184999823570251\n",
            "min validation loss 1.792044758796692\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003131310222670436\n",
            "last validation accuracy 0.8184999823570251\n",
            "last validation loss 1.792044758796692\n",
            "================================================================================\n",
            "Number of parameters = 42000, 52 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[326   0   8   2   3  13   6   6   3   3]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 335  15   1   4   9  10  26  10]\n",
            " [  4   3  16 310   2  38   1  11  16   7]\n",
            " [  0   3   3   6 361   5  15   2   3  20]\n",
            " [ 11   1   1  12   7 290   5   9  22  14]\n",
            " [ 14   2  28   0  17  17 295   1   4   0]\n",
            " [  0  10   3  13   5   2   0 350   1  27]\n",
            " [  8   7  11  22  12  22   5   5 272  20]\n",
            " [  4   5   1  13  27   2   0  17   5 317]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_78 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 52)                40820     \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 10)                530       \n",
            "=================================================================\n",
            "Total params: 41,350\n",
            "Trainable params: 41,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.003036429174244404\n",
            "max validation accuracy 0.8192499876022339\n",
            "min validation loss 1.7970499992370605\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.003036429174244404\n",
            "last validation accuracy 0.8192499876022339\n",
            "last validation loss 1.7970499992370605\n",
            "================================================================================\n",
            "Number of parameters = 46000, 57 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[323   0   8   2   3  13   7   6   4   4]\n",
            " [  0 420   4   6   3   0   5   2   8   2]\n",
            " [  6   2 333  17   1   3   9  10  27  10]\n",
            " [  3   2  16 314   2  35   1  11  17   7]\n",
            " [  0   3   3   6 364   3  16   2   3  18]\n",
            " [ 11   1   1  12   7 285   5   9  26  15]\n",
            " [ 11   2  26   0  17  19 297   1   5   0]\n",
            " [  0  11   3  13   5   2   0 347   1  29]\n",
            " [  7   7  10  21  13  20   5   5 275  21]\n",
            " [  4   5   1  13  27   2   0  16   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_79 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 57)                44745     \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 10)                580       \n",
            "=================================================================\n",
            "Total params: 45,325\n",
            "Trainable params: 45,325\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.002950782421976328\n",
            "max validation accuracy 0.8190000057220459\n",
            "min validation loss 1.7889515161514282\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.002950782421976328\n",
            "last validation accuracy 0.8190000057220459\n",
            "last validation loss 1.7889515161514282\n",
            "================================================================================\n",
            "Number of parameters = 50000, 62 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   8   2   3  10   6   6   4   3]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 336  15   1   4   9  10  25  10]\n",
            " [  4   3  16 310   2  37   1  11  16   8]\n",
            " [  0   3   3   6 364   3  14   2   3  20]\n",
            " [ 11   1   2  12   7 283   5   9  26  16]\n",
            " [ 14   2  30   0  17  17 292   1   5   0]\n",
            " [  0  11   1  13   6   2   0 349   1  28]\n",
            " [  8   8  11  21  13  21   6   5 271  20]\n",
            " [  4   5   1  13  27   2   0  16   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_80 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 62)                48670     \n",
            "_________________________________________________________________\n",
            "dense_161 (Dense)            (None, 10)                630       \n",
            "=================================================================\n",
            "Total params: 49,300\n",
            "Trainable params: 49,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0029607759788632393\n",
            "max validation accuracy 0.8180000185966492\n",
            "min validation loss 1.7937358617782593\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0029607759788632393\n",
            "last validation accuracy 0.8180000185966492\n",
            "last validation loss 1.7937358617782593\n",
            "================================================================================\n",
            "Number of parameters = 80000, 100 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[326   0   8   2   3  11   6   6   4   4]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 333  17   1   3   9  11  26  10]\n",
            " [  4   2  16 313   2  36   1  11  16   7]\n",
            " [  0   3   3   6 359   3  13   2   3  26]\n",
            " [ 12   1   2  12   8 281   5   9  26  16]\n",
            " [ 14   2  28   0  18  19 291   1   5   0]\n",
            " [  0  10   2  13   5   2   0 349   1  29]\n",
            " [  8   7  10  23  12  21   5   5 273  20]\n",
            " [  4   5   1  14  25   0   0  16   5 321]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_81 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0030473791994154453\n",
            "max validation accuracy 0.8167499899864197\n",
            "min validation loss 1.802910327911377\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0030473791994154453\n",
            "last validation accuracy 0.8167499899864197\n",
            "last validation loss 1.802910327911377\n",
            "================================================================================\n",
            "Number of parameters = 150000, 188 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[328   0   8   2   3  10   6   6   4   3]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 336  15   1   4   9  10  25  10]\n",
            " [  3   4  16 310   2  39   1  11  15   7]\n",
            " [  0   3   3   6 360   3  15   2   2  24]\n",
            " [ 13   1   1  12   8 284   5   9  25  14]\n",
            " [ 14   2  28   0  19  18 293   0   4   0]\n",
            " [  0  10   3  12   5   2   0 350   1  28]\n",
            " [  8   7  11  21  12  22   5   5 273  20]\n",
            " [  4   4   1  13  27   1   0  18   5 318]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_82 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_164 (Dense)            (None, 188)               147580    \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 10)                1890      \n",
            "=================================================================\n",
            "Total params: 149,470\n",
            "Trainable params: 149,470\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0032857467886060476\n",
            "max validation accuracy 0.8182500004768372\n",
            "min validation loss 1.8134820461273193\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0032857467886060476\n",
            "last validation accuracy 0.8182500004768372\n",
            "last validation loss 1.8134820461273193\n",
            "================================================================================\n",
            "Number of parameters = 300000, 377 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 0\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[327   0   8   2   3  11   6   6   3   4]\n",
            " [  0 421   4   6   3   0   5   2   7   2]\n",
            " [  6   2 337  13   1   4   8  11  26  10]\n",
            " [  3   1  16 308   2  39   1  12  18   8]\n",
            " [  0   2   3   5 362   2  14   2   2  26]\n",
            " [ 12   0   2  10   8 282   4  10  28  16]\n",
            " [ 14   2  27   0  17  17 295   1   5   0]\n",
            " [  0  11   4  10   5   2   0 350   1  28]\n",
            " [  8   7  11  18  13  22   5   5 273  22]\n",
            " [  4   4   1  12  27   1   0  14   6 322]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_83 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 377)               295945    \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 10)                3780      \n",
            "=================================================================\n",
            "Total params: 299,725\n",
            "Trainable params: 299,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0043746093288064\n",
            "max validation accuracy 0.8192499876022339\n",
            "min validation loss 1.820597529411316\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0043746093288064\n",
            "last validation accuracy 0.8192499876022339\n",
            "last validation loss 1.820597529411316\n",
            "================================================================================\n",
            "Number of parameters = 800000, 1006 hidden layer neurons\n",
            "================================================================================\n",
            "[1.0] False True\n",
            "STOPPING EARLY AFTER INTERPOLATING AT EPOCH 9\n",
            "INTERPOLATION THRESHOLD REACHED\n",
            "tf.Tensor(\n",
            "[[331   0  10   2   3   7   7   4   3   3]\n",
            " [  0 426   4   6   1   1   5   1   5   1]\n",
            " [  3   2 342  19   2   2   5  13  22   8]\n",
            " [  3   4  18 309   1  35   2  11  16   9]\n",
            " [  0   2   6   2 362   3  11   2   3  27]\n",
            " [ 10   3   2  11   6 289   6  10  23  12]\n",
            " [ 11   2  26   0  14  17 305   0   3   0]\n",
            " [  0  11   3  10   6   3   0 353   1  24]\n",
            " [  5   8   8  20   8  23   5   3 284  20]\n",
            " [  3   4   1  13  24   3   0  12   5 326]], shape=(10, 10), dtype=int32)\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_84 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 1006)              789710    \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 10)                10070     \n",
            "=================================================================\n",
            "Total params: 799,780\n",
            "Trainable params: 799,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "max training accuracy 1.0\n",
            "min training loss 0.0009957371512427926\n",
            "max validation accuracy 0.8317499756813049\n",
            "min validation loss 1.7540444135665894\n",
            "\n",
            "last training accuracy 1.0\n",
            "last training loss 0.0009957371512427926\n",
            "last validation accuracy 0.8317499756813049\n",
            "last validation loss 1.7540444135665894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f94f3524d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOaMYivifD5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}