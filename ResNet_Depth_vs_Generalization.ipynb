{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "\n",
    "from resnet import MNIST_ResNet\n",
    "from train_utils import Model_Trainer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST Data Set\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Normalize Image to be floats in range [0,1]\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Shuffle the Data set and set training batch size \n",
    "ds_train = ds_train.map(normalize_img)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples, reshuffle_each_iteration=True)\n",
    "ds_train = ds_train.batch(128)\n",
    "\n",
    "# Initilialize the Test Training data set\n",
    "ds_test = ds_test.map(normalize_img)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0 - Train Loss: 2.3207, Train Accuracy: 8.5938\n",
      "Epoch 1, Batch 25 - Train Loss: 2.1428, Train Accuracy: 31.5805\n",
      "Epoch 1, Batch 50 - Train Loss: 1.9781, Train Accuracy: 52.5889\n",
      "Epoch 1, Batch 75 - Train Loss: 1.8558, Train Accuracy: 65.6044\n",
      "Epoch 1, Batch 100 - Train Loss: 1.7810, Train Accuracy: 72.7336\n",
      "Epoch 1, Batch 125 - Train Loss: 1.7296, Train Accuracy: 77.4616\n",
      "Epoch 1, Batch 150 - Train Loss: 1.6941, Train Accuracy: 80.5878\n",
      "Epoch 1, Batch 175 - Train Loss: 1.6682, Train Accuracy: 82.8569\n",
      "Epoch 1, Batch 200 - Train Loss: 1.6478, Train Accuracy: 84.6743\n",
      "Epoch 1, Batch 225 - Train Loss: 1.6311, Train Accuracy: 86.1069\n",
      "Epoch 1, Batch 250 - Train Loss: 1.6181, Train Accuracy: 87.2012\n",
      "Epoch 1, Batch 275 - Train Loss: 1.6070, Train Accuracy: 88.1425\n",
      "Epoch 1, Batch 300 - Train Loss: 1.5976, Train Accuracy: 88.9457\n",
      "Epoch 1, Batch 325 - Train Loss: 1.5895, Train Accuracy: 89.6137\n",
      "Epoch 1, Batch 350 - Train Loss: 1.5821, Train Accuracy: 90.2444\n",
      "Epoch 1, Batch 375 - Train Loss: 1.5759, Train Accuracy: 90.7663\n",
      "Epoch 1, Batch 400 - Train Loss: 1.5705, Train Accuracy: 91.2134\n",
      "Epoch 1, Batch 425 - Train Loss: 1.5658, Train Accuracy: 91.6025\n",
      "Epoch 1, Batch 450 - Train Loss: 1.5616, Train Accuracy: 91.9484\n",
      "Epoch 1 - Train Loss: 1.5586, Train Accuracy: 92.1933, Test Loss: 1.5848, Test Accuracy: 90.2300\n",
      "Epoch 2, Batch 0 - Train Loss: 1.4846, Train Accuracy: 98.4375\n",
      "Epoch 2, Batch 25 - Train Loss: 1.4813, Train Accuracy: 98.6779\n",
      "Epoch 2, Batch 50 - Train Loss: 1.4819, Train Accuracy: 98.5447\n",
      "Epoch 2, Batch 75 - Train Loss: 1.4809, Train Accuracy: 98.6020\n",
      "Epoch 2, Batch 100 - Train Loss: 1.4803, Train Accuracy: 98.6077\n",
      "Epoch 2, Batch 125 - Train Loss: 1.4797, Train Accuracy: 98.6669\n",
      "Epoch 2, Batch 150 - Train Loss: 1.4791, Train Accuracy: 98.7376\n",
      "Epoch 2, Batch 175 - Train Loss: 1.4793, Train Accuracy: 98.7349\n",
      "Epoch 2, Batch 200 - Train Loss: 1.4793, Train Accuracy: 98.7562\n",
      "Epoch 2, Batch 225 - Train Loss: 1.4793, Train Accuracy: 98.7624\n",
      "Epoch 2, Batch 250 - Train Loss: 1.4793, Train Accuracy: 98.7581\n",
      "Epoch 2, Batch 275 - Train Loss: 1.4790, Train Accuracy: 98.7857\n",
      "Epoch 2, Batch 300 - Train Loss: 1.4789, Train Accuracy: 98.7905\n",
      "Epoch 2, Batch 325 - Train Loss: 1.4789, Train Accuracy: 98.7826\n",
      "Epoch 2, Batch 350 - Train Loss: 1.4790, Train Accuracy: 98.7647\n",
      "Epoch 2, Batch 375 - Train Loss: 1.4789, Train Accuracy: 98.7741\n",
      "Epoch 2, Batch 400 - Train Loss: 1.4790, Train Accuracy: 98.7609\n",
      "Epoch 2, Batch 425 - Train Loss: 1.4790, Train Accuracy: 98.7603\n",
      "Epoch 2, Batch 450 - Train Loss: 1.4791, Train Accuracy: 98.7510\n",
      "Epoch 2 - Train Loss: 1.4790, Train Accuracy: 98.7517, Test Loss: 1.4757, Test Accuracy: 99.0600\n",
      "Epoch 3, Batch 0 - Train Loss: 1.4680, Train Accuracy: 100.0000\n",
      "Epoch 3, Batch 25 - Train Loss: 1.4784, Train Accuracy: 98.7680\n",
      "Epoch 3, Batch 50 - Train Loss: 1.4785, Train Accuracy: 98.7592\n",
      "Epoch 3, Batch 75 - Train Loss: 1.4770, Train Accuracy: 98.9206\n",
      "Epoch 3, Batch 100 - Train Loss: 1.4781, Train Accuracy: 98.8088\n",
      "Epoch 3, Batch 125 - Train Loss: 1.4779, Train Accuracy: 98.8281\n",
      "Epoch 3, Batch 150 - Train Loss: 1.4778, Train Accuracy: 98.8307\n",
      "Epoch 3, Batch 175 - Train Loss: 1.4779, Train Accuracy: 98.8193\n",
      "Epoch 3, Batch 200 - Train Loss: 1.4780, Train Accuracy: 98.7990\n",
      "Epoch 3, Batch 225 - Train Loss: 1.4780, Train Accuracy: 98.7936\n",
      "Epoch 3, Batch 250 - Train Loss: 1.4778, Train Accuracy: 98.8203\n",
      "Epoch 3, Batch 275 - Train Loss: 1.4775, Train Accuracy: 98.8338\n",
      "Epoch 3, Batch 300 - Train Loss: 1.4773, Train Accuracy: 98.8502\n",
      "Epoch 3, Batch 325 - Train Loss: 1.4771, Train Accuracy: 98.8808\n",
      "Epoch 3, Batch 350 - Train Loss: 1.4772, Train Accuracy: 98.8626\n",
      "Epoch 3, Batch 375 - Train Loss: 1.4772, Train Accuracy: 98.8676\n",
      "Epoch 3, Batch 400 - Train Loss: 1.4771, Train Accuracy: 98.8700\n",
      "Epoch 3, Batch 425 - Train Loss: 1.4769, Train Accuracy: 98.8886\n",
      "Epoch 3, Batch 450 - Train Loss: 1.4767, Train Accuracy: 98.9017\n",
      "Epoch 3 - Train Loss: 1.4766, Train Accuracy: 98.9183, Test Loss: 1.4766, Test Accuracy: 98.9300\n",
      "Epoch 4, Batch 0 - Train Loss: 1.4705, Train Accuracy: 99.2188\n",
      "Epoch 4, Batch 25 - Train Loss: 1.4716, Train Accuracy: 99.3690\n",
      "Epoch 4, Batch 50 - Train Loss: 1.4745, Train Accuracy: 99.0809\n",
      "Epoch 4, Batch 75 - Train Loss: 1.4745, Train Accuracy: 99.0748\n",
      "Epoch 4, Batch 100 - Train Loss: 1.4746, Train Accuracy: 99.0563\n",
      "Epoch 4, Batch 125 - Train Loss: 1.4748, Train Accuracy: 99.0389\n",
      "Epoch 4, Batch 150 - Train Loss: 1.4746, Train Accuracy: 99.0377\n",
      "Epoch 4, Batch 175 - Train Loss: 1.4745, Train Accuracy: 99.0501\n",
      "Epoch 4, Batch 200 - Train Loss: 1.4748, Train Accuracy: 99.0283\n",
      "Epoch 4, Batch 225 - Train Loss: 1.4750, Train Accuracy: 99.0148\n",
      "Epoch 4, Batch 250 - Train Loss: 1.4749, Train Accuracy: 99.0320\n",
      "Epoch 4, Batch 275 - Train Loss: 1.4750, Train Accuracy: 99.0263\n",
      "Epoch 4, Batch 300 - Train Loss: 1.4750, Train Accuracy: 99.0189\n",
      "Epoch 4, Batch 325 - Train Loss: 1.4748, Train Accuracy: 99.0270\n",
      "Epoch 4, Batch 350 - Train Loss: 1.4747, Train Accuracy: 99.0429\n",
      "Epoch 4, Batch 375 - Train Loss: 1.4746, Train Accuracy: 99.0525\n",
      "Epoch 4, Batch 400 - Train Loss: 1.4747, Train Accuracy: 99.0454\n",
      "Epoch 4, Batch 425 - Train Loss: 1.4747, Train Accuracy: 99.0500\n",
      "Epoch 4, Batch 450 - Train Loss: 1.4746, Train Accuracy: 99.0542\n",
      "Epoch 4 - Train Loss: 1.4745, Train Accuracy: 99.0650, Test Loss: 1.4745, Test Accuracy: 99.1200\n",
      "Epoch 5, Batch 0 - Train Loss: 1.4724, Train Accuracy: 99.2188\n",
      "Epoch 5, Batch 25 - Train Loss: 1.4735, Train Accuracy: 99.1286\n",
      "Epoch 5, Batch 50 - Train Loss: 1.4731, Train Accuracy: 99.1422\n",
      "Epoch 5, Batch 75 - Train Loss: 1.4721, Train Accuracy: 99.2188\n",
      "Epoch 5, Batch 100 - Train Loss: 1.4722, Train Accuracy: 99.2110\n",
      "Epoch 5, Batch 125 - Train Loss: 1.4725, Train Accuracy: 99.1878\n",
      "Epoch 5, Batch 150 - Train Loss: 1.4726, Train Accuracy: 99.1929\n",
      "Epoch 5, Batch 175 - Train Loss: 1.4722, Train Accuracy: 99.2276\n",
      "Epoch 5, Batch 200 - Train Loss: 1.4725, Train Accuracy: 99.1993\n",
      "Epoch 5, Batch 225 - Train Loss: 1.4725, Train Accuracy: 99.1945\n",
      "Epoch 5, Batch 250 - Train Loss: 1.4724, Train Accuracy: 99.2032\n",
      "Epoch 5, Batch 275 - Train Loss: 1.4725, Train Accuracy: 99.1904\n",
      "Epoch 5, Batch 300 - Train Loss: 1.4727, Train Accuracy: 99.1565\n",
      "Epoch 5, Batch 325 - Train Loss: 1.4729, Train Accuracy: 99.1373\n",
      "Epoch 5, Batch 350 - Train Loss: 1.4728, Train Accuracy: 99.1542\n",
      "Epoch 5, Batch 375 - Train Loss: 1.4727, Train Accuracy: 99.1689\n",
      "Epoch 5, Batch 400 - Train Loss: 1.4728, Train Accuracy: 99.1506\n",
      "Epoch 5, Batch 425 - Train Loss: 1.4729, Train Accuracy: 99.1417\n",
      "Epoch 5, Batch 450 - Train Loss: 1.4729, Train Accuracy: 99.1339\n",
      "Epoch 5 - Train Loss: 1.4729, Train Accuracy: 99.1450, Test Loss: 1.4744, Test Accuracy: 99.0200\n"
     ]
    }
   ],
   "source": [
    "image_dim = ds_info.features['image'].shape\n",
    "n_classes = ds_info.features['label'].num_classes \n",
    "filter_n_0 = 16\n",
    "block_depth = 2\n",
    "# k is a width scaling parameter - when we down sample (1 < stride), increase number of features by a factor of 2k\n",
    "k = 1 \n",
    "\n",
    "residual_block_params = [\n",
    "    {'n_filters': 16, 'block_depth': block_depth, 'stride': 1},\n",
    "    {'n_filters': 32, 'block_depth': block_depth, 'stride': 2}\n",
    "]\n",
    "\n",
    "depth = block_depth * len(residual_block_params) + 1\n",
    "\n",
    "resnet = MNIST_ResNet(\n",
    "    input_shape=image_dim,\n",
    "    residual_block_params=residual_block_params,\n",
    "    n_classes=n_classes,\n",
    "    filter_n_0=filter_n_0\n",
    ")\n",
    "\n",
    "# Model_id should identify the the model set up. \n",
    "# i.e. effective depth, width scaling, initial layer width \n",
    "model_id = 'convolution_depth_{depth}_width_scale_{k}_filters_{filter_n_0}'\n",
    "\n",
    "\n",
    "starter_learning_rate = 1e-3\n",
    "end_learning_rate = 1e-4\n",
    "decay_steps = 500\n",
    "lr_schedule = PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.5)\n",
    "\n",
    "trainer = Model_Trainer(\n",
    "    model=resnet, \n",
    "    lr=lr_schedule,\n",
    "    model_id=model_id\n",
    ")\n",
    "\n",
    "n_epochs = 5\n",
    "steps = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    trainer.reset()\n",
    "    batch_count = 0\n",
    "    \n",
    "    for images, labels in ds_train:\n",
    "        train_loss, train_accuracy = trainer.train_step(images, labels)\n",
    "        \n",
    "        if batch_count % 25 == 0:\n",
    "            template = 'Epoch {}, Batch {} - Train Loss: {:.4f}, Train Accuracy: {:.4f}'\n",
    "            print(template.format(epoch + 1, batch_count, train_loss, train_accuracy))\n",
    "        batch_count += 1\n",
    "        steps += 1\n",
    "    \n",
    "    for images, labels in ds_test:\n",
    "        test_loss, test_accuracy = trainer.test_step(images, labels)\n",
    "    \n",
    "    template = 'Epoch {} - Train Loss: {:.4f}, Train Accuracy: {:.4f}, Test Loss: {:.4f}, Test Accuracy: {:.4f}'\n",
    "    print(template.format(epoch + 1, train_loss, train_accuracy, test_loss, test_accuracy))\n",
    "    \n",
    "    trainer.model_checkpoint()\n",
    "    trainer.log_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist__res_net_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           multiple                  416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc multiple                  64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 14, 14, 16)        14304     \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   (None, 7, 7, 32)          52320     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 67,434\n",
      "Trainable params: 66,762\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
